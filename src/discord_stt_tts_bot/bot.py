import io, os, wave, asyncio, tempfile, traceback, struct, math,re, time,csv, json
import audioop
import collections
import shutil
import discord
import typing as T

from datetime import datetime, timezone
from dotenv import load_dotenv
from discord import StageChannel, TextChannel, Thread
from discord.abc import Messageable
from discord.ext import commands, tasks
from gtts import gTTS
from openai import OpenAI
from pathlib import Path
import requests

try:
    import webrtcvad
except ImportError:  # pragma: no cover - optional dependency guard
    webrtcvad = None

# === CCFOLIA BRIDGE START: import ===
from aiohttp import web
# === CCFOLIA BRIDGE END: import ===

PACKAGE_DIR = Path(__file__).resolve().parent
SRC_DIR = PACKAGE_DIR.parent
if SRC_DIR.name == "src":
    PROJECT_ROOT = SRC_DIR.parent
else:
    PROJECT_ROOT = PACKAGE_DIR.parent

# å„ªå…ˆã—ã¦ãƒªãƒã‚¸ãƒˆãƒªç›´ä¸‹ã® .env ã‚’èª­ã¿è¾¼ã‚€ã€‚å­˜åœ¨ã—ãªã„ç’°å¢ƒã§ã¯æ—¢å®šã®æ¤œç´¢ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã€‚
dotenv_loaded = False
candidate_env = PROJECT_ROOT / ".env"
if candidate_env.exists():
    dotenv_loaded = load_dotenv(candidate_env)
if not dotenv_loaded:
    load_dotenv()
TOKEN = os.getenv("DISCORD_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
TTS_LANG = os.getenv("TTS_LANG", "ja")
TTS_PROVIDER = os.getenv("TTS_PROVIDER", "gtts").strip().lower() or "gtts"
VOICEVOX_BASE_URL = (os.getenv("VOICEVOX_BASE_URL", "http://127.0.0.1:50021").strip().rstrip("/"))
VOICEVOX_TIMEOUT = float(os.getenv("VOICEVOX_TIMEOUT", "15"))
VOICEVOX_DEFAULT_SPEAKER = int(os.getenv("VOICEVOX_DEFAULT_SPEAKER", "2"))
FFMPEG_BIN = os.getenv("FFMPEG_BIN", "ffmpeg")
ARNNDN_MODEL = os.getenv("ARNNDN_MODEL_PATH", "").strip()
DEFAULT_PRIMARY_STT_MODEL = os.getenv("STT_PRIMARY_MODEL", "gpt-4o-mini-transcribe").strip() or "gpt-4o-mini-transcribe"
DEFAULT_FALLBACK_STT_MODEL = os.getenv("STT_FALLBACK_MODEL", "gpt-4o-transcribe").strip() or "gpt-4o-transcribe"
_DEFAULT_STT_COSTS = {
    "gpt-4o-mini-transcribe": 0.0006,  # USD per audio minute (è¿‘ä¼¼)
    "gpt-4o-transcribe": 0.0015,
    "whisper-1": 0.0006,
}
try:
    _STT_COST_OVERRIDES = json.loads(os.getenv("STT_MODEL_COSTS_JSON", "{}"))
    if not isinstance(_STT_COST_OVERRIDES, dict):
        _STT_COST_OVERRIDES = {}
except Exception:
    _STT_COST_OVERRIDES = {}
# === CCFOLIA BRIDGE START: env ===
CCFO_HOST = os.getenv("CCFOLIA_BRIDGE_HOST", "127.0.0.1")
CCFO_PORT = int(os.getenv("CCFOLIA_BRIDGE_PORT", "8800"))
CCFO_SECRET = os.getenv("CCFOLIA_POST_SECRET", "")
CCFO_ACCEPT_FROM = {x.strip() for x in os.getenv("CCFOLIA_ACCEPT_FROM", "127.0.0.1,::1").split(",")}
CCFO_MIRROR_CH_ID = int(os.getenv("CCFOLIA_MIRROR_CHANNEL_ID", "0") or "0")
CCFO_TTS_MODE = os.getenv("CCFOLIA_TTS_MODE", "file").strip().lower()  # file/voice/off
CCFO_SPK_MAP = json.loads(os.getenv("CCFOLIA_SPEAKER_MAP_JSON", '{"ï¼ˆæœªæŒ‡å®šï¼‰":2}'))
CCFO_DEFAULT_SPK = int(os.getenv("CCFOLIA_DEFAULT_SPEAKER", "2"))
# ã‚¤ãƒ™ãƒ³ãƒˆã‚­ãƒ¥ãƒ¼
ccfo_queue: "asyncio.Queue[dict]" = asyncio.Queue()
# === CCFOLIA BRIDGE END: env ===

# STTå­—å¹•ç”¨ã®åŸºæœ¬16è‰²ï¼ˆè¦–èªæ€§ã®é«˜ã„è‰²ã‚’é¸æŠï¼‰
STT_COLOR_PALETTE: list[int] = [
    0xF44336, 0xE91E63, 0x9C27B0, 0x673AB7,
    0x3F51B5, 0x2196F3, 0x03A9F4, 0x00BCD4,
    0x009688, 0x4CAF50, 0x8BC34A, 0xCDDC39,
    0xFFC107, 0xFF9800, 0xFF5722, 0x795548,
]

def _resolve_log_dir(base_dir: Path, env_value: str | None) -> Path:
    # ç©º or æœªè¨­å®š â†’ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ "logs"
    if not env_value or not env_value.strip():
        return base_dir / "logs"
    # ~ ã¨ ç’°å¢ƒå¤‰æ•° ã‚’å±•é–‹
    expanded = os.path.expanduser(os.path.expandvars(env_value.strip()))
    p = Path(expanded)
    # ç›¸å¯¾ãƒ‘ã‚¹ãªã‚‰ PROJECT_ROOT åŸºæº–ã«
    if not p.is_absolute():
        p = base_dir / p
    return p

LOG_DIR = _resolve_log_dir(PROJECT_ROOT, os.getenv("LOG_DIR"))
TTS_LOG_PATH = LOG_DIR / "tts_logs.csv"
STT_LOG_PATH = LOG_DIR / "stt_logs.csv"
STT_METRICS_PATH = LOG_DIR / "stt_metrics.csv"
CCFO_LOG_PATH = LOG_DIR / "ccfolia_event_logs.csv"
_log_lock = asyncio.Lock()  # è¤‡æ•°ã‚¿ã‚¹ã‚¯ã‹ã‚‰ã®åŒæ™‚æ›¸ãè¾¼ã¿ã‚’ä¿è­·
print(f"[LOG] output directory: {LOG_DIR}")  # èµ·å‹•æ™‚ã«å‡ºåŠ›å…ˆã‚’è¡¨ç¤º

def _ensure_csv_with_header(path: Path, headers: list[str]):
    path.parent.mkdir(parents=True, exist_ok=True)
    if not path.exists():
        with open(path, "w", newline="", encoding="utf-8") as f:
            w = csv.writer(f)
            w.writerow(headers)

# åˆæœŸåŒ–ï¼ˆãƒ˜ãƒƒãƒ€è¡Œã‚’ç”¨æ„ï¼‰
_ensure_csv_with_header(
    TTS_LOG_PATH,
    ["timestamp_iso", "guild_id", "channel_id", "message_id", "author_id", "author_display", "text"],
)
_ensure_csv_with_header(
    STT_LOG_PATH,
    ["timestamp_iso", "guild_id", "dest_channel_id", "user_id", "user_display", "text", "duration_sec", "rms", "dbfs"],
)
_ensure_csv_with_header(
    STT_METRICS_PATH,
    [
        "timestamp_iso",
        "guild_id",
        "user_id",
        "model",
        "fallback_used",
        "duration_sec",
        "avg_logprob",
        "no_speech_prob",
        "compression_ratio",
        "token_count",
        "estimated_cost_usd",
        "text_length",
    ],
)
_ensure_csv_with_header(
    CCFO_LOG_PATH,
    ["timestamp_iso", "user_display", "text"],
)

def _norm_text_for_csv(text: str) -> str:
    return (text or "").replace("\r", " ").replace("\n", " ").strip()

async def _append_csv(path: Path, row: list):
    async with _log_lock:
        # å¤±æ•—ã—ã¦ã‚‚ bot å…¨ä½“ã‚’æ­¢ã‚ãªã„
        try:
            with open(path, "a", newline="", encoding="utf-8") as f:
                w = csv.writer(f)
                w.writerow(row)
        except Exception as e:
            print(f"[LOG] write failed for {path.name}:", repr(e))

async def log_tts_event(message: discord.Message, spoken_text: str):
    """èª­ã¿ä¸Šã’ãŸãƒ†ã‚­ã‚¹ãƒˆã®ãƒ­ã‚°ï¼ˆå…¥åŠ›è€…ãƒ»å…¥åŠ›æ™‚åˆ»ä»˜ãï¼‰"""
    ts = message.created_at
    if ts.tzinfo is None:
        ts = ts.replace(tzinfo=timezone.utc)
    row = [
        ts.astimezone(timezone.utc).isoformat(),
        message.guild.id if message.guild else 0,
        message.channel.id if hasattr(message, "channel") else 0,
        message.id,
        message.author.id if message.author else 0,
        (message.author.display_name if isinstance(message.author, discord.Member) else getattr(message.author, "name", "unknown")),
        _norm_text_for_csv(spoken_text),
    ]
    await _append_csv(TTS_LOG_PATH, row)

async def log_stt_event(
    guild_id: int,
    dest_channel_id: int | None,
    user_id: int,
    user_display: str,
    text: str,
    duration: float | None,
    rms: float | None,
    dbfs: float | None,
):
    """éŸ³å£°èªè­˜çµæœã®ãƒ­ã‚°ï¼ˆç™ºè¨€è€…ãƒ»ç™ºè¨€æ™‚é–“ï¼ˆè¨˜éŒ²æ™‚åˆ»ï¼‰ä»˜ãï¼‰"""
    ts = datetime.now(timezone.utc).isoformat()
    row = [
        ts,
        guild_id or 0,
        dest_channel_id or 0,
        user_id,
        user_display,
        _norm_text_for_csv(text),
        f"{duration:.3f}" if isinstance(duration, (int, float)) else "",
        f"{rms:.6f}" if isinstance(rms, (int, float)) else "",
        f"{dbfs:.2f}" if isinstance(dbfs, (int, float)) else "",
    ]
    await _append_csv(STT_LOG_PATH, row)


async def log_stt_metrics(
    guild_id: int,
    user_id: int,
    model: str,
    fallback_used: bool,
    duration: float | None,
    avg_logprob: float | None,
    no_speech_prob: float | None,
    compression_ratio: float | None,
    token_count: int | None,
    estimated_cost: float | None,
    text_length: int,
):
    ts = datetime.now(timezone.utc).isoformat()
    row = [
        ts,
        guild_id or 0,
        user_id,
        model or "",
        int(bool(fallback_used)),
        f"{duration:.3f}" if isinstance(duration, (int, float)) else "",
        f"{avg_logprob:.3f}" if isinstance(avg_logprob, (int, float)) else "",
        f"{no_speech_prob:.3f}" if isinstance(no_speech_prob, (int, float)) else "",
        f"{compression_ratio:.3f}" if isinstance(compression_ratio, (int, float)) else "",
        str(int(token_count)) if isinstance(token_count, (int, float)) else "",
        f"{estimated_cost:.6f}" if isinstance(estimated_cost, (int, float)) else "",
        str(int(text_length)) if isinstance(text_length, (int, float)) else "",
    ]
    await _append_csv(STT_METRICS_PATH, row)


def _evaluate_transcription_response(resp, text: str, duration: float | None) -> tuple[dict, bool]:
    metrics: dict[str, float | int | None] = {
        "avg_logprob": None,
        "no_speech_prob": None,
        "compression_ratio": None,
        "token_count": None,
    }
    segments = getattr(resp, "segments", None)
    avg_logprob_acc: list[float] = []
    token_total = 0
    if isinstance(segments, (list, tuple)):
        for seg in segments:
            if isinstance(seg, dict):
                val = seg.get("avg_logprob")
                if isinstance(val, (int, float)):
                    avg_logprob_acc.append(float(val))
                ns = seg.get("no_speech_prob")
                if metrics["no_speech_prob"] is None and isinstance(ns, (int, float)):
                    metrics["no_speech_prob"] = float(ns)
                tokens = seg.get("tokens")
                if isinstance(tokens, (list, tuple)):
                    token_total += len(tokens)
    if avg_logprob_acc:
        metrics["avg_logprob"] = sum(avg_logprob_acc) / len(avg_logprob_acc)
    comp = getattr(resp, "compression_ratio", None)
    if isinstance(comp, (int, float)):
        metrics["compression_ratio"] = float(comp)
    if token_total > 0:
        metrics["token_count"] = token_total
    else:
        tokens_attr = getattr(resp, "tokens", None)
        if isinstance(tokens_attr, (list, tuple)):
            metrics["token_count"] = len(tokens_attr)

    should_retry = False
    text_len = len(text or "")
    dur = duration or 0.0
    avg_logprob = metrics["avg_logprob"]
    no_speech_prob = metrics["no_speech_prob"]
    compression_ratio = metrics["compression_ratio"]

    if isinstance(avg_logprob, (int, float)) and avg_logprob < -0.7:
        should_retry = True
    if isinstance(no_speech_prob, (int, float)) and no_speech_prob > 0.8:
        should_retry = True
    if isinstance(compression_ratio, (int, float)) and compression_ratio > 2.4:
        should_retry = True
    if text_len <= 4 and dur >= 2.0:
        should_retry = True

    return metrics, should_retry

async def log_ccfolia_event(
    user_display: str,
    text: str,
):
    print(['log:',CCFO_LOG_PATH,',',user_display,',',text])
    """ã‚³ã‚³ãƒ•ã‚©ãƒªã‚¢é€£æºã®ãƒ­ã‚°ï¼ˆç™ºè¨€è€…ãƒ»ç™ºè¨€æ™‚é–“ï¼ˆè¨˜éŒ²æ™‚åˆ»ï¼‰ä»˜ãï¼‰"""
    ts = datetime.now(timezone.utc).isoformat()
    row = [
        ts,
        user_display,
        _norm_text_for_csv(text),
    ]
    await _append_csv(CCFO_LOG_PATH, row)

if OPENAI_API_KEY:
    print(f"[STT] OPENAI_API_KEY detected.")
else:
    print("[STT] OPENAI_API_KEY NOT found (Whisperã¯å‹•ãã¾ã›ã‚“)")

intents = discord.Intents.default()
intents.message_content = True
intents.guilds = True
intents.voice_states = True
intents.messages = True
intents.members = True

bot = commands.Bot(command_prefix=("!", "ï¼"), intents=intents, help_command=None)
openai = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None

guild_state = {}  # guild_id -> dict( read_channel_id, stt_on, record_window )

DEFAULT_WINDOW = 10  # ç§’ã”ã¨ã«éŒ²éŸ³ã‚’åŒºåˆ‡ã£ã¦å­—å¹•åŒ–

# === è¿½åŠ ï¼šè©±é€Ÿãƒ»å£°è‰²ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã¨FFmpegãƒ•ã‚£ãƒ«ã‚¿ç”Ÿæˆ ===
VOICE_PROFILES = [
    {"name": "alto",     "semitones": -2, "tempo": 1.15},  # ã¡ã‚‡ã„ä½ã‚ãƒ»ã‚„ã‚„é€Ÿã„
    {"name": "neutral",  "semitones":  0, "tempo": 1.25},  # æ¨™æº–ãƒ”ãƒƒãƒãƒ»é€Ÿã„
    {"name": "bright",   "semitones": +4, "tempo": 1.20},  # é«˜ã‚ãƒ»å°‘ã—é€Ÿã„
    {"name": "deep",     "semitones": -5, "tempo": 1.12},  # ä½ã‚ãƒ»å°‘ã—é€Ÿã„
]

def _atempo_chain(x: float) -> list[str]:
    # FFmpegã® atempo ã¯ 0.5ã€œ2.0 ã®ç¯„å›²ãªã®ã§åˆ†å‰²
    chain = []
    while x > 2.0:
        chain.append("atempo=2.0")
        x /= 2.0
    while x < 0.5:
        chain.append("atempo=0.5")
        x /= 0.5
    chain.append(f"atempo={x:.4f}")
    return chain

def _build_ffmpeg_afilter(semitones: float, final_tempo: float) -> str:
    """
    semitones: ãƒ”ãƒƒãƒä¸Šä¸‹ï¼ˆ+ã§é«˜ãï¼‰
    final_tempo: æœ€çµ‚çš„ãªè©±é€Ÿå€ç‡ï¼ˆ>1ã§é€Ÿã„ï¼‰
    ãƒ”ãƒƒãƒã¯ asetrate ã§ä¸Šã’ä¸‹ã’ â†’ atempo ã§é€Ÿåº¦ã‚’èª¿æ•´ã€‚
    """
    # ãƒ”ãƒƒãƒä¿‚æ•°ï¼ˆåŠéŸ³Ã—12 â†’ 2^(n/12)ï¼‰
    pitch_factor = 2.0 ** (semitones / 12.0)
    # asetrate ã§é€Ÿåº¦ã‚‚ pitch_factor å€ã«ãªã‚‹ã®ã§ã€atempo ã§ç›®æ¨™è©±é€Ÿã¸è£œæ­£
    # ã¤ã¾ã‚Š total_atempo = final_tempo / pitch_factor
    total_atempo = final_tempo / max(pitch_factor, 1e-6)

    # ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆã¯ 48kHz ã«çµ±ä¸€ï¼ˆDiscordå‘ã‘ã«å®‰å®šï¼‰
    parts = [f"asetrate=48000*{pitch_factor:.6f}", "aresample=48000"]
    parts += _atempo_chain(total_atempo)
    # ã‚«ãƒ³ãƒã§é€£çµãƒ»ã‚¹ãƒšãƒ¼ã‚¹ä¸è¦ï¼ˆWindowsã®ffmpegã§ã®ã‚¯ã‚©ãƒ¼ãƒˆå›é¿ï¼‰
    return ",".join(parts)

def _dbfs_from_rms(rms: float) -> float:
    if rms <= 1e-9:
        return -120.0
    return 20.0 * math.log10(rms)

def jp_cleanup(text: str) -> str:
    t = re.sub(r"\s+", " ", (text or "").strip())
    if not t:
        return t
    # æœ«å°¾ã«å¥èª­ç‚¹ãŒç„¡ã‘ã‚Œã°ã€Œã€‚ã€ã‚’ä»˜ã‘ã‚‹ï¼ˆè‹±æ•°ã§çµ‚ã‚ã‚‹ãªã‚‰ä»˜ã‘ãªã„ï¼‰
    if not re.search(r"[ã€‚ï¼ï¼Ÿ!?]$", t) and re.search(r"[ã-ã‚“ã‚¡-ãƒ³ä¸€-é¾¥]", t):
        t += "ã€‚"
    return t

async def post_caption(guild_id: int, channel, user_id: int, username: str, new_text: str):
    st = get_state(guild_id)
    now = time.monotonic()
    ch_id = str(getattr(channel, "id", 0))
    key_u = str(user_id)

    ch_map = st["last_msgs"].setdefault(ch_id, {})
    entry = ch_map.get(key_u)
    color = _resolve_caption_color(guild_id, user_id)

    # ç›´è¿‘ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒã‚ã£ã¦ merge_window å†…ãªã‚‰ç·¨é›†ã§è¿½è¨˜
    if entry and entry.get("message") and (now - entry.get("ts", 0)) < st["merge_window"]:
        try:
            base_text = entry.get("text", "")
            merged = (base_text + " " + new_text).strip()
            embed = _build_caption_embed(username, merged, color)
            await entry["message"].edit(embed=embed)
            entry["text"] = merged
            entry["ts"] = now
            return
        except Exception as e:
            print("[STT] edit failed; fallback send:", repr(e))

    # æ–°è¦æŠ•ç¨¿
    embed = _build_caption_embed(username, new_text, color)
    m = await channel.send(embed=embed)
    ch_map[key_u] = {"message": m, "ts": now, "text": new_text}

async def resolve_display_name(guild: discord.Guild, user_id: int, data=None) -> str:
    # 1) Sink ãŒ user ã‚’æŒã£ã¦ã„ã‚Œã°æœ€å„ªå…ˆ
    u = getattr(data, "user", None)
    if u:
        if isinstance(u, discord.Member):
            return u.display_name
        # discord.User
        return getattr(u, "global_name", None) or u.name

    # 2) ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆMembers Intent æœ‰åŠ¹ãªã‚‰ã“ã“ã§å–ã‚Œã‚‹ï¼‰
    m = guild.get_member(user_id)
    if m:
        return m.display_name

    # 3) API ãƒ•ã‚§ãƒƒãƒï¼ˆGuild Memberï¼‰
    try:
        m = await guild.fetch_member(user_id)
        return m.display_name
    except Exception:
        pass

    # 4) ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¦ãƒ¼ã‚¶ãƒ¼
    u = bot.get_user(user_id)
    if u:
        return getattr(u, "global_name", None) or u.name
    try:
        u = await bot.fetch_user(user_id)
        return getattr(u, "global_name", None) or u.name
    except Exception:
        pass

    # 5) æœ€å¾Œã®æ‰‹æ®µï¼šIDã®æœ«å°¾ã ã‘è¦‹ã›ã‚‹
    return f"ä¸æ˜ãƒ¦ãƒ¼ã‚¶ãƒ¼({str(user_id)[-6:]})"

def _rms_from_frames(frames: bytes, sampwidth: int) -> float:
    """PCMãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆãƒªãƒˆãƒ«ã‚¨ãƒ³ãƒ‡ã‚£ã‚¢ãƒ³ï¼‰ã‹ã‚‰RMSã‚’è¿”ã™ã€‚æˆ»ã‚Šå€¤ã¯0.0ã€œ1.0ã«æ­£è¦åŒ–ã€‚"""
    if not frames:
        return 0.0

    if sampwidth == 1:
        # 8bitã¯ unsignedã€‚0..255 ã‚’ -128..127 ã«å¤‰æ›ã—ã¦RMS
        n = len(frames)
        if n == 0: return 0.0
        acc = 0
        for b in frames:
            s = b - 128
            acc += s * s
        mean_sq = acc / n
        return math.sqrt(mean_sq) / 127.0

    elif sampwidth == 2:
        # 16bit signed little-endian
        cnt = len(frames) // 2
        if cnt == 0: return 0.0
        vals = struct.unpack("<%dh" % cnt, frames[:cnt*2])
        acc = 0
        for v in vals:
            acc += v * v
        mean_sq = acc / cnt
        return math.sqrt(mean_sq) / 32767.0

    elif sampwidth == 3:
        # 24bit signed little-endianï¼ˆ3ãƒã‚¤ãƒˆã”ã¨ã«èª­ã¿å–ã‚Šï¼‰
        cnt = len(frames) // 3
        if cnt == 0: return 0.0
        acc = 0
        for i in range(cnt):
            b0 = frames[3*i]
            b1 = frames[3*i+1]
            b2 = frames[3*i+2]
            # 24bitç¬¦å·æ‹¡å¼µ
            u = b0 | (b1 << 8) | (b2 << 16)
            if u & 0x800000:
                u = u - 0x1000000
            acc += u * u
        mean_sq = acc / cnt
        return math.sqrt(mean_sq) / 8388607.0  # 2^23-1

    elif sampwidth == 4:
        # 32bit signed little-endian
        cnt = len(frames) // 4
        if cnt == 0: return 0.0
        vals = struct.unpack("<%di" % cnt, frames[:cnt*4])
        acc = 0
        for v in vals:
            acc += v * v
        mean_sq = acc / cnt
        return math.sqrt(mean_sq) / 2147483647.0  # 2^31-1

    else:
        # æœªå¯¾å¿œã®å¹…ã¯0æ‰±ã„
        return 0.0

def _pick_fallback_text_channel(g: discord.Guild) -> T.Optional[discord.TextChannel]:
    """ãã®ã‚®ãƒ«ãƒ‰ã§BotãŒé€ä¿¡ã§ãã‚‹é©å½“ãªTextChannelã‚’è¿”ã™"""
    if not g: 
        return None
    # 1) ã‚·ã‚¹ãƒ†ãƒ ãƒãƒ£ãƒ³ãƒãƒ«ãŒé€ä¿¡å¯ãªã‚‰å„ªå…ˆ
    sysch = g.system_channel
    if sysch:
        perms = sysch.permissions_for(g.me)
        if perms.view_channel and perms.send_messages:
            return sysch
    # 2) ä»–ã®ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ãƒãƒ«ã§é€ä¿¡å¯ãªã‚‚ã®
    for ch in g.text_channels:
        perms = ch.permissions_for(g.me)
        if perms.view_channel and perms.send_messages:
            return ch
    return None

async def resolve_message_channel(channel_id: int, guild_id: int) -> T.Optional[discord.abc.Messageable]:
    """channel_id ã‹ã‚‰ã€Œé€ä¿¡å¯èƒ½ãªMessageableã€ã‚’è¿”ã™ã€‚ã‚¹ãƒ¬ãƒƒãƒ‰ã¯å¿…è¦ãªã‚‰unarchiveã™ã‚‹ã€‚"""
    ch = bot.get_channel(channel_id)  # ã‚­ãƒ£ãƒƒã‚·ãƒ¥
    src = "cache"
    if ch is None:
        try:
            ch = await bot.fetch_channel(channel_id)  # API
            src = "api"
        except discord.Forbidden:
            print(f"[STT] fetch_channel forbidden for {channel_id}")
            ch = None
        except discord.NotFound:
            print(f"[STT] fetch_channel notfound for {channel_id}")
            ch = None
        except Exception as e:
            print("[STT] fetch_channel failed:", repr(e))
            ch = None

    if ch is not None:
        print(f"[STT] resolve hit ({src}): type={type(ch).__name__} id={getattr(ch,'id',None)}")
        # ã‚¹ãƒ¬ãƒƒãƒ‰ãªã‚‰å¿…è¦ã«å¿œã˜ã¦unarchive
        if isinstance(ch, discord.Thread) and ch.archived:
            try:
                await ch.edit(archived=False, locked=False)
                print("[STT] thread unarchived")
            except Exception as e:
                print("[STT] thread unarchive failed:", repr(e))
        # Messageableï¼ˆ.sendã§ãã‚‹ï¼‰ãªã‚‰OK
        if isinstance(ch, Messageable) or hasattr(ch, "send"):
            return ch

    # ã“ã“ã¾ã§ã§è§£æ±ºã§ããªã„ãªã‚‰ã€åŒã‚®ãƒ«ãƒ‰ã§ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    g = bot.get_guild(guild_id)
    fb = _pick_fallback_text_channel(g)
    if fb:
        print(f"[STT] fallback to #{fb.name} ({fb.id})")
        return fb

    print("[STT] no messageable channel available")
    return None

def wav_stats(src):
    """
    src: ãƒ‘ã‚¹/bytes/BytesIO/file-like ã‚’å—ã‘å–ã‚Šã€
    (duration_sec, normalized_rms) ã‚’è¿”ã™ã€‚rmsã¯0.0ã€œ1.0ã€‚
    """
    need_close = False
    if isinstance(src, (str, os.PathLike)):
        f = open(src, "rb"); need_close = True
    elif isinstance(src, (bytes, bytearray, memoryview)):
        f = io.BytesIO(src)
    else:
        f = src  # file-like
    try:
        try: f.seek(0)
        except: pass
        with wave.open(f, "rb") as wf:
            nframes = wf.getnframes()
            fr = wf.getframerate()
            sw = wf.getsampwidth()
            dur = (nframes / fr) if fr else 0.0
            wf.rewind()
            # å…ˆé ­10ç§’åˆ†ã ã‘ã§RMSã‚’è¨ˆç®—
            frames = wf.readframes(min(nframes, fr * 10))
            rms_norm = _rms_from_frames(frames, sw)
        return dur, rms_norm
    finally:
        if need_close:
            f.close()


def _wav_bytes_to_pcm16k(src: bytes) -> bytes | None:
    """WaveSinkãŒç”Ÿæˆã—ãŸWAVã‚’16kHz/mono/16bit PCMã¸å¤‰æ›ã™ã‚‹ã€‚"""
    try:
        with wave.open(io.BytesIO(src), "rb") as wf:
            rate = wf.getframerate()
            width = wf.getsampwidth()
            channels = wf.getnchannels()
            frames = wf.readframes(wf.getnframes())
    except Exception:
        traceback.print_exc()
        return None

    if not frames:
        return None

    try:
        if channels > 1:
            frames = audioop.tomono(frames, width, 1.0, 1.0)
        if width != 2:
            frames = audioop.lin2lin(frames, width, 2)
            width = 2
        if rate != 16000:
            frames, _ = audioop.ratecv(frames, 2, 1, rate, 16000, None)
    except Exception:
        traceback.print_exc()
        return None

    return frames


def _pcm16k_to_wav_bytes(pcm: bytes, sample_rate: int = 16000) -> bytes:
    buff = io.BytesIO()
    with wave.open(buff, "wb") as wf:
        wf.setnchannels(1)
        wf.setsampwidth(2)
        wf.setframerate(sample_rate)
        wf.writeframes(pcm)
    return buff.getvalue()


class _VadUserStream:
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼å˜ä½ã§éŸ³å£°ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å—ã‘å–ã‚Šã€VADåŒºåˆ‡ã‚Šã‚’è¡Œã†ã€‚"""

    FRAME_MS = 20
    SAMPLE_RATE = 16000
    SAMPLE_WIDTH = 2

    def __init__(self):
        self._vad: webrtcvad.Vad | None = None if webrtcvad is None else webrtcvad.Vad(2)
        self._config: dict[str, int] = {}
        self._pre_buffer: collections.deque[bytes] = collections.deque()
        self._active: list[bytes] = []
        self._prev_tail: list[bytes] = []
        self._in_speech = False
        self._silence_counter = 0
        self._post_counter = -1
        self._silence_frames = 8
        self._post_frames = 0
        self._overlap_frames = 0
        self._max_segment_frames = 1200
        self._min_frames = 1

    def configure(self, st: dict):
        if webrtcvad is None:
            raise RuntimeError("webrtcvad is not available")

        cfg = dict(
            aggressiveness=int(max(0, min(3, st.get("vad_aggressiveness", 2))))
        )
        frame_ms = self.FRAME_MS
        cfg["pre_frames"] = max(0, int(st.get("vad_pre_ms", 200) // frame_ms))
        cfg["silence_frames"] = max(1, int(st.get("vad_silence_ms", 450) // frame_ms))
        cfg["post_frames"] = max(0, int(st.get("vad_post_ms", 400) // frame_ms))
        cfg["overlap_frames"] = max(0, int(st.get("vad_overlap_ms", 320) // frame_ms))
        cfg["min_frames"] = max(1, int(st.get("min_dur", 0.8) * 1000 // frame_ms))
        cfg["max_segment_frames"] = max(
            cfg["overlap_frames"] + cfg["silence_frames"] + 1,
            int(st.get("vad_max_segment_ms", 20000) // frame_ms)
        )

        if cfg != self._config:
            self._config = cfg
            self._vad = webrtcvad.Vad(cfg["aggressiveness"])
            self._pre_buffer = collections.deque(maxlen=cfg["pre_frames"] or 1)
            self._silence_frames = cfg["silence_frames"]
            self._post_frames = cfg["post_frames"]
            self._overlap_frames = cfg["overlap_frames"]
            self._max_segment_frames = max(cfg["max_segment_frames"], cfg["pre_frames"] + cfg["overlap_frames"] + 4)
            self._min_frames = cfg["min_frames"]

    def feed(self, wav_bytes: bytes, st: dict) -> list[bytes]:
        if webrtcvad is None:
            return []
        self.configure(st)
        pcm = _wav_bytes_to_pcm16k(wav_bytes)
        if not pcm:
            return []

        frame_bytes = int(self.SAMPLE_RATE * self.FRAME_MS / 1000) * self.SAMPLE_WIDTH
        outputs: list[bytes] = []

        for offset in range(0, len(pcm), frame_bytes):
            frame = pcm[offset:offset + frame_bytes]
            if len(frame) < frame_bytes:
                # ç«¯æ•°ã¯æ¬¡ã‚µã‚¤ã‚¯ãƒ«ã¸å›ã™ï¼ˆæ¨ã¦ã‚‹ï¼‰
                break

            is_speech = self._vad.is_speech(frame, self.SAMPLE_RATE) if self._vad else False

            if is_speech:
                if not self._in_speech:
                    starter: list[bytes] = []
                    if self._prev_tail and self._overlap_frames:
                        starter.extend(self._prev_tail)
                    if self._config.get("pre_frames"):
                        starter.extend(self._pre_buffer)
                    if starter:
                        self._active.extend(starter)
                    self._prev_tail = []
                    self._in_speech = True
                self._active.append(frame)
                self._silence_counter = 0
                self._post_counter = -1
            else:
                if self._in_speech:
                    self._active.append(frame)
                    self._silence_counter += 1
                    if self._silence_counter >= self._silence_frames:
                        if self._post_counter < 0:
                            self._post_counter = self._post_frames
                        self._post_counter -= 1
                        if self._post_counter <= 0:
                            seg = self._finalize_segment()
                            if seg:
                                outputs.append(_pcm16k_to_wav_bytes(seg))
                # ã‚µã‚¤ãƒ¬ãƒ³ãƒˆçŠ¶æ…‹ãŒç¶šãå ´åˆã‚‚ãƒ—ãƒªãƒãƒƒãƒ•ã‚¡ã«ã¯ä¿æŒã™ã‚‹

            # ãƒ—ãƒªãƒ­ãƒ¼ãƒ«ç”¨ãƒªãƒ³ã‚°ãƒãƒƒãƒ•ã‚¡ã¯å¸¸ã«æœ€æ–°çŠ¶æ…‹ã«æ›´æ–°
            if self._pre_buffer.maxlen:
                self._pre_buffer.append(frame)

            if self._in_speech and len(self._active) >= self._max_segment_frames:
                seg = self._finalize_segment(force=True)
                if seg:
                    outputs.append(_pcm16k_to_wav_bytes(seg))

        return outputs

    def drain(self) -> list[bytes]:
        if not self._active:
            return []
        seg = self._finalize_segment(force=True)
        if not seg:
            return []
        return [_pcm16k_to_wav_bytes(seg)]

    def _finalize_segment(self, force: bool = False) -> bytes | None:
        if not self._active:
            self._reset_state()
            return None
        segment_frames = list(self._active)
        if not force and len(segment_frames) < self._min_frames:
            # çŸ­ã™ãã‚‹ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¯ãƒã‚¤ã‚ºã¨ã—ã¦ç ´æ£„
            self._reset_state()
            return None

        tail_count = min(self._overlap_frames, len(segment_frames))
        if tail_count:
            self._prev_tail = segment_frames[-tail_count:]
        else:
            self._prev_tail = []

        pcm = b"".join(segment_frames)
        self._reset_state()
        return pcm

    def _reset_state(self):
        self._active = []
        self._in_speech = False
        self._silence_counter = 0
        self._post_counter = -1


def _build_denoise_filter_chain(st: dict) -> str:
    filters: list[str] = []
    hp = int(st.get("denoise_highpass", 0) or 0)
    lp = int(st.get("denoise_lowpass", 0) or 0)
    if hp > 0:
        filters.append(f"highpass=f={hp}")
    if lp > 0:
        filters.append(f"lowpass=f={lp}")

    mode = (st.get("denoise_mode") or "").lower()
    if mode == "arnndn":
        model = (st.get("denoise_model") or "").strip()
        if model:
            filters.append(f"arnndn=m={model}")
        else:
            filters.append("arnndn")
    elif mode == "afftdn":
        strength = float(st.get("denoise_strength", 12.0) or 0.0)
        filters.append(f"afftdn=nr={strength:.1f}")

    gain = float(st.get("denoise_gain", 0.0) or 0.0)
    if gain > 0.0:
        filters.append(f"dynaudnorm=f=150:g={gain:.1f}")

    comp = (st.get("denoise_compand") or "").strip()
    if comp:
        filters.append(f"compand={comp}")

    return ",".join(filters)


async def _maybe_denoise_wav(raw: bytes, st: dict) -> bytes:
    if not raw or len(raw) <= 44:
        return raw
    if not st.get("denoise_enable", False):
        return raw
    if st.get("denoise_ffmpeg_failed"):
        return raw

    ffmpeg_path = shutil.which(FFMPEG_BIN)
    if not ffmpeg_path:
        st["denoise_ffmpeg_failed"] = True
        print("[STT] denoise skipped: ffmpeg not found")
        return raw

    filters = _build_denoise_filter_chain(st)
    if not filters:
        return raw

    try:
        proc = await asyncio.create_subprocess_exec(
            ffmpeg_path,
            "-hide_banner",
            "-loglevel", "error",
            "-i", "pipe:0",
            "-af", filters,
            "-f", "wav",
            "pipe:1",
            stdin=asyncio.subprocess.PIPE,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE,
        )
    except FileNotFoundError:
        st["denoise_ffmpeg_failed"] = True
        print("[STT] denoise skipped: ffmpeg execution failed")
        return raw

    try:
        stdout_data, stderr_data = await proc.communicate(raw)
    except Exception as exc:
        st["denoise_ffmpeg_failed"] = True
        print("[STT] denoise failed during execution:", repr(exc))
        return raw

    if proc.returncode != 0 or not stdout_data:
        st["denoise_ffmpeg_failed"] = True
        err_excerpt = (stderr_data or b"").decode("utf-8", errors="ignore").strip()
        if err_excerpt:
            print("[STT] denoise ffmpeg error:", err_excerpt)
        else:
            print("[STT] denoise ffmpeg returned empty output")
        return raw

    return stdout_data


def _estimate_stt_cost(model: str, duration_sec: float) -> float:
    rate = _STT_COST_OVERRIDES.get(model)
    if not isinstance(rate, (int, float)):
        rate = _DEFAULT_STT_COSTS.get(model, 0.0)
    try:
        minutes = max(0.0, float(duration_sec)) / 60.0
    except Exception:
        minutes = 0.0
    return minutes * float(rate)


async def transcribe_and_post(src, channel, username: str):
    if not openai:
        print("[STT] OpenAI client is None"); return
    tmp = None; fh = None
    try:
        # ãƒ‡ãƒãƒƒã‚°: åŒºåˆ‡ã‚Šã®é•·ã•ãƒ»éŸ³é‡
        try:
            dur, rms = wav_stats(src)
            print(f"[STT] segment stats: dur={dur:.2f}s rms={rms}")
        except Exception:
            traceback.print_exc()

        # Whisperã¸ã¯ãƒ•ã‚¡ã‚¤ãƒ«ã§æ¸¡ã™ï¼ˆBytesIOã¯ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«åŒ–ï¼‰
        if isinstance(src, (str, os.PathLike)):
            fh = open(src, "rb")
        else:
            if hasattr(src, "read"):
                try: src.seek(0)
                except: pass
                buf = src.read()
            else:
                buf = bytes(src)
            tf = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
            tmp = tf.name; tf.write(buf); tf.close()
            fh = open(tmp, "rb")

        resp = openai.audio.transcriptions.create(
            file=fh, model="whisper-1", language="ja"
        )
        text = (getattr(resp, "text", "") or "").strip()
        print(f"[STT] Whisper result: {text!r}")
        if text:
            await channel.send(f"ğŸ¤ **{username}**: {text}")
    except Exception as e:
        print("[STT] Transcription failed:", repr(e))
        traceback.print_exc()
    finally:
        try:
            if fh: fh.close()
        finally:
            if tmp:
                try: os.remove(tmp)
                except: pass

@bot.command(name="rectest", aliases=["éŒ²éŸ³ãƒ†ã‚¹ãƒˆ"])
async def rectest(ctx: commands.Context, seconds: int = 5):
    """ç¾åœ¨ã®ãƒœã‚¤ã‚¹CHã§ seconds ç§’ã ã‘éŒ²éŸ³ã—ã€WAVã‚’æ·»ä»˜ã—ã¦è¿”ã™"""
    vc = ctx.guild.voice_client
    if not vc or not vc.is_connected():
        return await ctx.reply("å…ˆã« `!join` ã—ã¦ãã ã•ã„ã€‚")

    if seconds < 2 or seconds > 30:
        return await ctx.reply("éŒ²éŸ³ç§’æ•°ã¯ 2ã€œ30 ç§’ã®ç¯„å›²ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚ ä¾‹: `!rectest 5`")

    # WaveSink ã§ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ¥ã«WAVã‚’ç”Ÿæˆ
    sink = discord.sinks.WaveSink()
    done = asyncio.Event()
    captured = []

    def _collect_filelike(fileobj) -> bytes:
        if isinstance(fileobj, (str, os.PathLike)):
            with open(fileobj, "rb") as rf:
                return rf.read()
        try:
            fileobj.seek(0)
        except Exception:
            pass
        return fileobj.read() if hasattr(fileobj, "read") else bytes(fileobj)

    async def finished_callback(sink, *args):
        try:
            # ã ã‚Œã®ãƒˆãƒ©ãƒƒã‚¯ãŒç”Ÿæˆã•ã‚ŒãŸã‹ã‚’ä¸€è¦§è¡¨ç¤º
            print("[STT] users in window:", list(sink.audio_data.keys()))
            for user_id, data in sink.audio_data.items():
                uid = int(user_id)

                # ã©ã®ãã‚‰ã„éŒ²ã‚ŒãŸã‹ï¼ˆpy-cordã®AudioDataã¯byte_countã‚’æŒã£ã¦ã„ã‚‹ã¯ãšï¼‰
                byte_count = getattr(data, "byte_count", None)

                # fileã‚µã‚¤ã‚ºï¼ˆWAVãªã‚‰ãƒ˜ãƒƒãƒ€è¾¼ã¿ã‚µã‚¤ã‚ºï¼‰
                size = None
                f = data.file
                if isinstance(f, (str, os.PathLike)):
                    try: size = os.path.getsize(f)
                    except: size = None
                else:
                    try:
                        pos = f.tell()
                        f.seek(0, os.SEEK_END)
                        size = f.tell()
                        f.seek(0)
                    except Exception:
                        size = None

                print(f"[STT] capture stat uid={uid} byte_count={byte_count} size={size}")

                # å…¸å‹çš„ãªã€Œç©ºWAVã€ï¼ˆãƒ˜ãƒƒãƒ€ã ã‘ â‰’ 44ãƒã‚¤ãƒˆï¼‰ã‚„ byte_count==0 ã¯å¼¾ã
                if (byte_count is not None and byte_count == 0) or (size is not None and size <= 44):
                    continue

                # å®Ÿãƒ‡ãƒ¼ã‚¿ã ã‘è¿½åŠ 
                buf = _collect_filelike(data.file)
                captured.append((uid, data, buf))
        finally:
            done.set()

    try:
        vc.start_recording(sink, finished_callback)
    except Exception as e:
        traceback.print_exc()
        return await ctx.reply(f"éŒ²éŸ³é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸ: {e!r}")

    await ctx.reply(f"ğŸ™ï¸ {seconds} ç§’ã ã‘éŒ²éŸ³ã—ã¾ã™ã€‚è©±ã—ã‹ã‘ã¦ãã ã•ã„â€¦")
    await asyncio.sleep(seconds)

    try:
        vc.stop_recording()
    except:
        pass

    await done.wait()

def _pick_voice_profile_for_user(guild_id: int, user_id: int | None) -> dict:
    """ã‚®ãƒ«ãƒ‰è¨­å®šã® override ã‚’æœ€å„ªå…ˆã€‚ãªã‘ã‚Œã°VOICESã‚’ user_id ã§å®‰å®šå‰²å½“ã€‚"""
    st = get_state(guild_id)
    if user_id is not None:
        ov = st["tts_overrides"].get(int(user_id))
        if ov:  # æ˜ç¤ºã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰
            return {"name": "custom", "semitones": ov.get("semitones", 0.0), "tempo": ov.get("tempo", 1.0)}
        # è‡ªå‹•å‰²å½“
        base = VOICE_PROFILES[user_id % len(VOICE_PROFILES)]
        return base
    return {"name": "neutral", "semitones": 0.0, "tempo": 1.0}

def get_state(guild_id):
    if guild_id not in guild_state:
        guild_state[guild_id] = dict(
            read_channel_id=None,
            stt_on=False,
            record_window=DEFAULT_WINDOW,
            stt_task=None,
            vad_rms=0.02,
            vad_db=-45.0,
            min_dur=0.8,
            merge_window=6.0,
            merge_auto=True,
            stt_mode="vad",  # vad | fixed
            vad_aggressiveness=2,
            vad_silence_ms=450,
            vad_pre_ms=200,
            vad_post_ms=400,
            vad_overlap_ms=320,
            vad_max_segment_ms=20000,
            denoise_enable=True,
            denoise_mode=("arnndn" if ARNNDN_MODEL else "afftdn"),
            denoise_model=ARNNDN_MODEL,
            denoise_highpass=120,
            denoise_lowpass=7000,
            denoise_strength=12.0,
            denoise_gain=15.0,
            denoise_compand="attacks=10:decays=100:points=-70/-90|-40/-20|0/-2",
            denoise_ffmpeg_failed=False,
            lang="ja",
            stt_primary_model=DEFAULT_PRIMARY_STT_MODEL,
            stt_fallback_model=DEFAULT_FALLBACK_STT_MODEL,
            use_thread=False,
            caption_dest_id=None,
            last_msgs={},
            rec_lock=asyncio.Lock(),
            tts_base_tempo=float(os.getenv("TTS_TEMPO", "0.7")),  # ã‚µãƒ¼ãƒãƒ¼å…¨ä½“ã®åŸºæº–è©±é€Ÿ
            tts_overrides={},   # { user_id: {"semitones": float, "tempo": float} }
            tts_default_speaker=VOICEVOX_DEFAULT_SPEAKER,
            tts_speakers={},    # { user_id: speaker_id }
            stt_color_overrides={},  # { user_id: palette_index }
            stt_metrics=dict(
                total_calls=0,
                fallback_calls=0,
                total_duration=0.0,
                total_cost=0.0,
                model_usage=collections.Counter(),
            ),
        )
    return guild_state[guild_id]


async def ensure_stopped(vc: discord.VoiceClient, why: str = ""):
    """éŒ²éŸ³ãŒæ®‹ã£ã¦ã„ã‚Œã°å¼·åˆ¶åœæ­¢ã—ã¦ã€å°‘ã—å¾…ã¤"""
    try:
        rec_flag = getattr(vc, "recording", False)
        print(f"[STT] ensure_stopped({why}) recording={rec_flag}")
        if rec_flag:
            try:
                vc.stop_recording()
                print("[STT] forced stop_recording()")
            except Exception as e:
                print("[STT] forced stop failed:", repr(e))
        await asyncio.sleep(0.25)  # ãƒ•ãƒ©ãƒƒã‚·ãƒ¥å¾…ã¡
    except Exception as e:
        print("[STT] ensure_stopped error:", repr(e))

def sanitize_for_tts(text: str) -> str:
    import re
    text = re.sub(r"<@!?\d+>", "ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³", text)
    text = re.sub(r"<@&\d+>", "ãƒ­ãƒ¼ãƒ«ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³", text)
    text = re.sub(r"<#\d+>", "ãƒãƒ£ãƒ³ãƒãƒ«", text)
    text = re.sub(r"https?://\S+", "ãƒªãƒ³ã‚¯", text)
    return text[:400]


def _resolve_caption_color(guild_id: int, user_id: int | None) -> int:
    """å­—å¹•ç”¨ã®Embedã‚«ãƒ©ãƒ¼ã‚’æ±ºå®šã™ã‚‹ã€‚"""
    st = get_state(guild_id)
    if user_id is not None:
        override = st["stt_color_overrides"].get(int(user_id))
        if isinstance(override, int) and 0 <= override < len(STT_COLOR_PALETTE):
            return STT_COLOR_PALETTE[override]
        idx = abs(int(user_id)) % len(STT_COLOR_PALETTE)
        return STT_COLOR_PALETTE[idx]
    return STT_COLOR_PALETTE[0]


def _build_caption_embed(username: str, text: str, color: int) -> discord.Embed:
    """å­—å¹•è¡¨ç¤ºç”¨ã®Embedã‚’ç”Ÿæˆã™ã‚‹ã€‚"""
    embed = discord.Embed(description=text, color=color)
    embed.set_author(name=username)
    return embed


def _voicevox_request(text: str, speaker_id: int) -> bytes:
    """VOICEVOX ã‚¨ãƒ³ã‚¸ãƒ³ã¸éŸ³å£°åˆæˆã‚’ä¾é ¼ã—ã€éŸ³å£°ãƒ‡ãƒ¼ã‚¿ï¼ˆWAVï¼‰ã®ãƒã‚¤ãƒŠãƒªã‚’è¿”ã™ã€‚"""
    params = {"text": text, "speaker": speaker_id}
    query_url = f"{VOICEVOX_BASE_URL}/audio_query"
    synth_url = f"{VOICEVOX_BASE_URL}/synthesis"

    try:
        query_resp = requests.post(query_url, params=params, timeout=VOICEVOX_TIMEOUT)
        query_resp.raise_for_status()
        query_payload = query_resp.json()
        synth_resp = requests.post(
            synth_url,
            params={"speaker": speaker_id},
            json=query_payload,
            timeout=VOICEVOX_TIMEOUT,
        )
        synth_resp.raise_for_status()
        return synth_resp.content
    except Exception as exc:
        print(f"[TTS] VOICEVOX synthesis failed: {exc!r}")
        raise


async def _voicevox_synthesize(text: str, speaker_id: int) -> bytes:
    """VOICEVOX ã¸ã®åŒæœŸãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œã—ã€éŸ³å£°ãƒã‚¤ãƒˆåˆ—ã‚’å–å¾—ã™ã‚‹ã€‚"""
    loop = asyncio.get_running_loop()
    return await loop.run_in_executor(None, lambda: _voicevox_request(text, speaker_id))

async def tts_play(guild: discord.Guild, text: str, speaker_id: int | None = None):
    vc: discord.VoiceClient = guild.voice_client
    if not vc or not vc.is_connected():
        return

    st = get_state(guild.id)
    if TTS_PROVIDER == "voicevox":
        fallback = await _tts_play_voicevox(vc, guild, text, speaker_id)
        if not fallback:
            return
        # VOICEVOX ãŒå¤±æ•—ã—ãŸå ´åˆã¯ fallback ã«ã‚ˆã‚Š gTTS å‘¼ã³å‡ºã—ã¸
    await _tts_play_gtts(vc, guild.id, text, speaker_id, st)


async def _play_vc_audio(vc: discord.VoiceClient, path: str):
    """æŒ‡å®šãƒ‘ã‚¹ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ ffmpeg çµŒç”±ã§å†ç”Ÿã™ã‚‹ã€‚"""
    audio = discord.FFmpegPCMAudio(
        path,
        before_options="-loglevel quiet -nostdin",
        options="-vn"
    )
    vc.play(audio)
    while vc.is_playing():
        await asyncio.sleep(0.2)


async def _tts_play_gtts(vc: discord.VoiceClient, guild_id: int, text: str, speaker_id: int | None, st: dict):
    """gTTS ã‚’ç”¨ã„ãŸå¾“æ¥ã®èª­ã¿ä¸Šã’ã‚’å®Ÿè¡Œã™ã‚‹ã€‚"""
    prof = _pick_voice_profile_for_user(guild_id, speaker_id)
    final_tempo = st["tts_base_tempo"] * prof.get("tempo", 1.0)
    final_tempo = max(0.5, min(2.5, final_tempo))
    semitones = float(prof.get("semitones", 0.0))

    with tempfile.NamedTemporaryFile(suffix=".mp3", delete=False) as f:
        tmp_path = f.name
    try:
        gTTS(text=sanitize_for_tts(text), lang=TTS_LANG).save(tmp_path)
        af = _build_ffmpeg_afilter(semitones=semitones, final_tempo=final_tempo)
        audio = discord.FFmpegPCMAudio(
            tmp_path,
            before_options="-loglevel quiet -nostdin",
            options=f"-vn -af {af}"
        )
        vc.play(audio)
        while vc.is_playing():
            await asyncio.sleep(0.2)
    finally:
        try:
            os.remove(tmp_path)
        except Exception:
            pass


async def _tts_play_voicevox(vc: discord.VoiceClient, guild: discord.Guild, text: str, speaker_id: int | None) -> bool:
    """VOICEVOX ã‚’ç”¨ã„ãŸèª­ã¿ä¸Šã’ã‚’å®Ÿè¡Œã™ã‚‹ã€‚æˆåŠŸã—ãŸã‚‰ Trueã€å¤±æ•—ã—ãŸå ´åˆã¯ False ã‚’è¿”ã™ã€‚"""
    resolved = _resolve_voicevox_speaker(guild.id, speaker_id)
    sanitized = sanitize_for_tts(text)
    try:
        audio_bytes = await _voicevox_synthesize(sanitized, resolved)
    except Exception as exc:
        print("[TTS] VOICEVOX fallback to gTTS due to:", repr(exc))
        try:
            await _notify_voicevox_failure(guild, resolved)
        except Exception as notify_exc:
            print("[TTS] Failed to notify VOICEVOX fallback:", repr(notify_exc))
        return True  # fallback: gTTS ã‚’ç¶šã‘ã‚‹

    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as f:
        tmp_path = f.name
        f.write(audio_bytes)

    try:
        await _play_vc_audio(vc, tmp_path)
        return False
    finally:
        try:
            os.remove(tmp_path)
        except Exception:
            pass


def _resolve_voicevox_speaker(guild_id: int, user_id: int | None) -> int:
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼å‘ã‘ã® VOICEVOX è©±è€… ID ã‚’æ±ºå®šã™ã‚‹ã€‚"""
    st = get_state(guild_id)
    if user_id is not None:
        sid = st["tts_speakers"].get(int(user_id))
        if isinstance(sid, int):
            return sid
    return int(st.get("tts_default_speaker", VOICEVOX_DEFAULT_SPEAKER))


async def _notify_voicevox_failure(guild: discord.Guild, speaker_id: int):
    """VOICEVOX å¤±æ•—æ™‚ã«èª­ã¿ä¸Šã’å¯¾è±¡ãƒãƒ£ãƒ³ãƒãƒ«ã¸é€šçŸ¥ã™ã‚‹ã€‚"""
    st = get_state(guild.id)
    channel_id = st.get("read_channel_id")
    channel: T.Optional[discord.abc.Messageable] = None
    if channel_id:
        channel = guild.get_channel(channel_id)
    if channel is None:
        channel = _pick_fallback_text_channel(guild)
    if channel is None:
        return
    note = (
        "ğŸ”„ VOICEVOX ã¸ã®æ¥ç¶šã«å¤±æ•—ã—ãŸãŸã‚ã€èª­ã¿ä¸Šã’ã‚’ gTTS ã«åˆ‡ã‚Šæ›¿ãˆã¾ã—ãŸã€‚\n"
        f"speaker_id={speaker_id}"
    )
    await channel.send(note)


async def _voicevox_fetch_json(method: str, path: str, *, params=None, json_payload=None):
    """VOICEVOX ã¨ã®åŒæœŸHTTPé€šä¿¡ã‚’ã‚¹ãƒ¬ãƒƒãƒ‰ã§è¡Œã†ãƒ˜ãƒ«ãƒ‘ãƒ¼ã€‚"""
    if TTS_PROVIDER != "voicevox":
        raise RuntimeError("VOICEVOX provider is disabled")

    def _request():
        url = f"{VOICEVOX_BASE_URL}{path}"
        resp = requests.request(method, url, params=params, json=json_payload, timeout=VOICEVOX_TIMEOUT)
        try:
            resp.raise_for_status()
        except requests.HTTPError as exc:
            detail = None
            try:
                detail_json = resp.json()
                detail = json.dumps(detail_json, ensure_ascii=False)
            except Exception:
                detail = resp.text
            msg = f"HTTP {resp.status_code}: {detail or str(exc)}"
            raise requests.HTTPError(msg, response=resp) from exc
        try:
            return resp.json()
        except ValueError:
            return None

    loop = asyncio.get_running_loop()
    return await loop.run_in_executor(None, _request)


async def _voicevox_list_dictionary() -> list[dict]:
    data = await _voicevox_fetch_json("GET", "/user_dict")
    items = []
    if isinstance(data, dict):
        items = [{"id": key, **value} for key, value in data.items()]
    elif isinstance(data, list):
        items = data
    items.sort(key=lambda x: (x.get("pronunciation") or "", x.get("surface") or ""))
    return items


async def _voicevox_add_dictionary_word(surface: str, pronunciation: str, accent_type: int | None = None, word_type: str = "PROPER_NOUN"):
    surface = (surface or "").strip()
    pronunciation = _normalize_pronunciation(pronunciation)
    accent = _sanitize_accent_type(pronunciation, accent_type)
    payload = {
        "surface": surface,
        "pronunciation": pronunciation,
        "word_type": word_type or "PROPER_NOUN",
        "accent_type": accent,
    }
    try:
        return await _voicevox_fetch_json("POST", "/user_dict_word", params=payload)
    except requests.HTTPError as exc:
        resp = getattr(exc, "response", None)
        detail = resp.text if resp is not None else str(exc)
        raise RuntimeError(f"VOICEVOX è¾æ›¸ç™»éŒ²ã«å¤±æ•—ã—ã¾ã—ãŸ: {detail}") from exc


def _sanitize_accent_type(pronunciation: str, accent_type: int | str | None) -> int:
    try:
        accent = int(accent_type) if accent_type is not None else 1
    except (TypeError, ValueError):
        accent = 1

    accent = max(0, accent)
    pron = (pronunciation or "").strip()
    if not pron:
        return accent

    max_len = max(1, len(pron))
    if accent > max_len:
        accent = max_len
    return accent


_HIRA_TO_KATA = str.maketrans({
    **{chr(h): chr(h + 0x60) for h in range(0x3041, 0x3097)},
    "ã‚”": "ãƒ´",
    "ã‚": "ãƒ°",
    "ã‚‘": "ãƒ±",
})


def _normalize_pronunciation(src: str | None) -> str:
    pron = (src or "").strip()
    if not pron:
        return ""
    pron = pron.translate(_HIRA_TO_KATA)
    pron = pron.replace("ã€€", " ").replace(" ", "")
    return pron


@bot.event
async def on_ready():
    print(f"Logged in as {bot.user} (py-cord)")
    for g in bot.guilds:
        get_state(g.id)

@bot.command(name="join", aliases=["åŸ·äº‹å‚åŠ ", "åŸ·äº‹å…¥å®¤", "åŸ·äº‹å¬å–š"])
async def join(ctx: commands.Context):
    if not ctx.author.voice or not ctx.author.voice.channel:
        return await ctx.reply("å…ˆã«ãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ«ã¸å…¥å®¤ã—ã¦ãã ã•ã„ã€‚")
    channel = ctx.author.voice.channel
    vc = ctx.guild.voice_client

    if vc and vc.channel and vc.channel.id == channel.id:
        return await ctx.reply(f"æ—¢ã« **{channel.name}** ã«æ¥ç¶šæ¸ˆã¿ã§ã™ã€‚")

    if vc:
        try:
            await ensure_stopped(vc, "before rejoin")
        except Exception:
            pass
        try:
            await vc.disconnect(force=True)
        except Exception as exc:
            print("[join] disconnect failed:", repr(exc))

    try:
        vc = await channel.connect()
    except discord.ClientException as exc:
        if "Already connected" in str(exc):
            existing = ctx.guild.voice_client
            if existing:
                try:
                    await existing.move_to(channel)
                    vc = existing
                except Exception as move_exc:
                    print("[join] move_to after Already connected failed:", repr(move_exc))
                    raise
            else:
                raise
        else:
            raise

    # ğŸ”§ Stage ã ã£ãŸã‚‰è©±è€…åŒ–ã‚’è©¦ã¿ã‚‹ï¼ˆå¤±æ•—ã—ã¦ã‚‚ç¶šè¡Œï¼‰
    if isinstance(channel, StageChannel):
        try:
            # è©±è€…ã«æ˜‡æ ¼ï¼ˆæ¨©é™ãŒå¿…è¦ã€‚ç„¡ã„å ´åˆã¯ except ã¸ï¼‰
            await ctx.guild.change_voice_state(channel=channel, suppress=False)
            # ã†ã¾ãã„ã‹ãªã„ç’°å¢ƒã§ã¯ã€Œè©±ã•ã›ã¦ãã ã•ã„ã€ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
            await ctx.guild.change_voice_state(channel=channel, request_to_speak=True)
            await ctx.reply("Stage ã§è©±è€…åŒ–ã‚’è©¦ã¿ã¾ã—ãŸã€‚ï¼ˆå¿…è¦ãªã‚‰ãƒ¢ãƒ‡ãƒ¬ãƒ¼ã‚¿ãƒ¼ãŒæ‰¿èªã—ã¦ãã ã•ã„ï¼‰")
        except Exception as e:
            print("[join] Stage unsuppress/request_to_speak failed:", repr(e))
            await ctx.reply("ã“ã®ãƒãƒ£ãƒ³ãƒãƒ«ã¯ Stage ã®ã‚ˆã†ã§ã™ã€‚éŒ²éŸ³ã«ã¯é€šå¸¸ã®ãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ«æ¨å¥¨ã§ã™ã€‚")

    st = get_state(ctx.guild.id)
    st["read_channel_id"] = ctx.channel.id
    # è¨ºæ–­ä¸Šã®è¦‹æ „ãˆç”¨ï¼ˆãƒ¯ãƒ¼ã‚«ãƒ¼ã¯ã“ã‚Œã«ä¾å­˜ã—ã¾ã›ã‚“ãŒ True ã«ã—ã¦ãŠãï¼‰
    st["stt_on"] = False
    await ctx.reply(f"Joined **{channel.name}**ã€‚ã“ã®ãƒãƒ£ãƒ³ãƒãƒ«ã‚’èª­ã¿ä¸Šã’å¯¾è±¡ã«è¨­å®šã—ã¾ã—ãŸã€‚")

@bot.command(name="diag", aliases=["è¨ºæ–­"])
async def diag(ctx: commands.Context):
    import shutil, platform
    vc = ctx.guild.voice_client
    mevoice = getattr(ctx.guild.me, "voice", None)
    ch_type = type(vc.channel).__name__ if (vc and vc.channel) else "None"
    try:
        pynacl_ok = True
        import nacl  # PyNaCl
    except Exception:
        pynacl_ok = False

    lines = [
        f"py-cord: {discord.__version__}",
        f"ffmpeg: {'OK' if shutil.which('ffmpeg') else 'NG'}",
        f"PyNaCl import: {pynacl_ok}",
        f"Opus loaded: {discord.opus.is_loaded()}",
        f"OPENAI_API_KEY: {'FOUND' if OPENAI_API_KEY else 'MISSING'}",
        f"Voice connected: {bool(vc and vc.is_connected())}",
        f"Bot self_deaf: {getattr(mevoice, 'self_deaf', None)}",
        f"STT on: {get_state(ctx.guild.id)['stt_on']}",
        f"Voice channel type: {ch_type}",
        f"Record window: {get_state(ctx.guild.id)['record_window']}s",
        f"OS: {platform.platform()}",
    ]
    await ctx.reply("ğŸ” **è¨ºæ–­**\n" + "\n".join(f"- {x}" for x in lines))

@bot.command(name="whereami")
async def whereami(ctx: commands.Context):
    ch = ctx.channel
    parent = getattr(ch, "parent", None)
    await ctx.reply(
        "ğŸ“Œ **ã“ã“ã¯ï¼Ÿ**\n"
        f"- type={type(ch).__name__}\n"
        f"- id={getattr(ch, 'id', None)}\n"
        f"- name={getattr(ch, 'name', None)}\n"
        f"- parent={getattr(parent, 'name', None)} ({getattr(parent, 'id', None)})"
    )

@bot.command(name="stttest", aliases=["æ–‡å­—èµ·ã“ã—ãƒ†ã‚¹ãƒˆ"])
async def stttest(ctx: commands.Context):
    if not openai:
        return await ctx.reply("OPENAI_API_KEY ãŒæœªè¨­å®šã§ã™ã€‚`.env` ã«è¨­å®šã—ã€å†èµ·å‹•ã—ã¦ãã ã•ã„ã€‚")
    import tempfile
    from gtts import gTTS
    with tempfile.NamedTemporaryFile(suffix=".mp3", delete=False) as f:
        tmp = f.name
    gTTS(text="ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆã§ã™ã€‚éŸ³å£°èªè­˜ã®ç¢ºèªã‚’ã—ã¦ã„ã¾ã™ã€‚", lang=TTS_LANG).save(tmp)
    try:
        with open(tmp, "rb") as audio:
            resp = openai.audio.transcriptions.create(
                file=audio, model="whisper-1", language="ja"
            )
        await ctx.reply(f"âœ… Whisperå¿œç­”: `{resp.text}`")
    except Exception as e:
        await ctx.reply(f"âŒ Whisperå¤±æ•—: {e!r}")
    finally:
        try: os.remove(tmp)
        except: pass

@bot.command(name="leave", aliases=["åŸ·äº‹é€€å‡º", "åŸ·äº‹é›¢è„±"])
async def leave(ctx: commands.Context):
    vc = ctx.guild.voice_client
    if vc and vc.is_connected():
        await vc.disconnect(force=True)
    st = get_state(ctx.guild.id)
    st["read_channel_id"] = None
    st["stt_on"] = False
    await ctx.reply("Left the voice channel.")

@bot.command(name="readon", aliases=["èª­ã¿ä¸Šã’ã‚³ãƒãƒ³ãƒ‰", "èª­ã¿ä¸Šã’", "èª­ã¿ä¸Šã’é–‹å§‹", "èª­ã¿ä¸Šã’ã‚ªãƒ³", "ã“ã®ãƒãƒ£ãƒ³ãƒãƒ«ã‚’èª­ã¿ä¸Šã’"])
async def readon(ctx: commands.Context):
    if not ctx.guild.voice_client or not ctx.guild.voice_client.is_connected():
        return await ctx.reply("å…ˆã« `!join` ã—ã¦ãã ã•ã„ã€‚")
    st = get_state(ctx.guild.id)
    st["read_channel_id"] = ctx.channel.id
    await ctx.reply("ã“ã®ãƒãƒ£ãƒ³ãƒãƒ«ã®æ–°è¦æŠ•ç¨¿ã‚’èª­ã¿ä¸Šã’ã¾ã™ã€‚`!readoff` ã§åœæ­¢ã€‚")

@bot.command(name="readoff", aliases=["èª­ã¿ä¸Šã’åœæ­¢", "èª­ã¿ä¸Šã’ã‚ªãƒ•"])
async def readoff(ctx: commands.Context):
    st = get_state(ctx.guild.id)
    st["read_channel_id"] = None
    await ctx.reply("èª­ã¿ä¸Šã’ã‚’åœæ­¢ã—ã¾ã—ãŸã€‚")

@bot.command(name="stton", aliases=["å­—å¹•é–‹å§‹","æ–‡å­—èµ·ã“ã—é–‹å§‹","å­—å¹•ã‚ªãƒ³","éŸ³å£°èªè­˜é–‹å§‹"])
async def stton(ctx: commands.Context, *args: str):
    vc = ctx.guild.voice_client
    if not vc or not vc.is_connected():
        return await ctx.reply("å…ˆã« `!join` ã—ã¦ãã ã•ã„ã€‚")
    st = get_state(ctx.guild.id)

    desired_mode = st.get("stt_mode", "vad")
    window_override: int | None = None

    for raw in args:
        if raw is None:
            continue
        token = raw.strip()
        if not token:
            continue
        lowered = token.lower()
        if lowered in ("vad", "auto", "adaptive"):
            desired_mode = "vad"
        elif lowered in ("fixed", "timer", "window", "legacy"):
            desired_mode = "fixed"
        else:
            try:
                win = int(token)
            except ValueError:
                return await ctx.reply("`vad` / `fixed` / åŒºåˆ‡ã‚Šç§’æ•°(3-60) ã®ã„ãšã‚Œã‹ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
            if not (3 <= win <= 60):
                return await ctx.reply("åŒºåˆ‡ã‚Šç§’æ•°ã¯ 3ã€œ60 ã®ç¯„å›²ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
            window_override = win
            desired_mode = "fixed"

    if window_override is not None:
        st["record_window"] = window_override
        if st.get("merge_auto", True):
            st["merge_window"] = max(st["merge_window"], round(window_override * 1.25, 2))

    st["stt_mode"] = desired_mode

    # æ—¢å­˜ã‚¿ã‚¹ã‚¯åœæ­¢
    if st.get("stt_task") and not st["stt_task"].done():
        st["stt_task"].cancel()
        try: await st["stt_task"]
        except: pass

    # ğŸ” é€ä¿¡å…ˆãƒãƒ£ãƒ³ãƒãƒ«ã‚’â€œä»Šã“ã“â€ã‹ã‚‰è§£æ±ºï¼ˆVoiceChannelãªã‚‰ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
    dest = await resolve_message_channel(ctx.channel.id, ctx.guild.id)
    if dest is None:
        return await ctx.reply("é€ä¿¡å¯èƒ½ãªãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ãƒãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚æ¨©é™ã‚’ã”ç¢ºèªãã ã•ã„ã€‚")

    print(f"[STT] stton from channel: id={ctx.channel.id} type={type(ctx.channel).__name__} -> post to id={dest.id} type={type(dest).__name__}")

    # ãƒ¯ãƒ¼ã‚«ãƒ¼ã«ã¯ â€œè§£æ±ºæ¸ˆã¿ã®é€ä¿¡å…ˆIDâ€ ã‚’æ¸¡ã™
    st["stt_task"] = asyncio.create_task(stt_worker(ctx.guild.id, dest.id))
    st["stt_on"] = True

    mode_text = "VADãƒ¢ãƒ¼ãƒ‰" if desired_mode == "vad" else f"å›ºå®š{st['record_window']}ç§’åŒºåˆ‡ã‚Š"
    await ctx.reply(
        f"ğŸ§ éŸ³å£°èªè­˜ã‚’é–‹å§‹ï¼ˆ{mode_text}ï¼‰ã€‚æŠ•ç¨¿å…ˆ: <#{dest.id}> / OpenAIéµ: {'ã‚ã‚Š' if openai else 'ãªã—'}"
    )


@bot.command(name="sttoff", aliases=["å­—å¹•åœæ­¢","å­—å¹•çµ‚äº†","æ–‡å­—èµ·ã“ã—åœæ­¢","å­—å¹•ã‚ªãƒ•","éŸ³å£°èªè­˜åœæ­¢"])
async def sttoff(ctx: commands.Context):
    st = get_state(ctx.guild.id)
    if st.get("stt_task") and not st["stt_task"].done():
        st["stt_task"].cancel()
        try: await st["stt_task"]
        except: pass
    st["stt_task"] = None
    # â˜… å¿µã®ãŸã‚åœæ­¢
    vc = ctx.guild.voice_client
    if vc and vc.is_connected():
        await ensure_stopped(vc, "manual off")
    await ctx.reply("éŸ³å£°èªè­˜ã‚’åœæ­¢ã—ã¾ã—ãŸã€‚")


@bot.command(name="sttstats", aliases=["sttçµ±è¨ˆ", "sttmetrics"])
async def sttstats(ctx: commands.Context):
    st = get_state(ctx.guild.id)
    metrics = st.get("stt_metrics") or {}
    total = metrics.get("total_calls", 0)
    fallback = metrics.get("fallback_calls", 0)
    duration = metrics.get("total_duration", 0.0)
    cost = metrics.get("total_cost", 0.0)
    usage = metrics.get("model_usage")
    lines = []
    lines.append(f"ç·ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆæ•°: {total}")
    if total:
        lines.append(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç™ºç”Ÿ: {fallback} ({(fallback/total)*100:.1f}%)")
    else:
        lines.append("ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç™ºç”Ÿ: 0")
    lines.append(f"ç´¯è¨ˆéŸ³å£°é•·: {duration:.1f} ç§’")
    lines.append(f"æ¨å®šã‚³ã‚¹ãƒˆ: ${cost:.4f}")
    if isinstance(usage, collections.Counter) and usage:
        top_models = usage.most_common(5)
        model_text = ", ".join(f"{name}:{count}" for name, count in top_models)
        lines.append(f"ãƒ¢ãƒ‡ãƒ«ä½¿ç”¨å›æ•°: {model_text}")
    await ctx.reply("STTæŒ‡æ¨™æ¦‚è¦:\n" + "\n".join(lines))


@bot.command(name="readhere", aliases=["ã“ã“ã‚’èª­ã¿ä¸Šã’"])
async def readhere(ctx: commands.Context):
    if not ctx.guild.voice_client or not ctx.guild.voice_client.is_connected():
        return await ctx.reply("å…ˆã« `!join` ã—ã¦ãã ã•ã„ã€‚")
    st = get_state(ctx.guild.id)
    st["read_channel_id"] = ctx.channel.id
    await ctx.reply("ã“ã®ãƒãƒ£ãƒ³ãƒãƒ«ã‚’èª­ã¿ä¸Šã’å¯¾è±¡ã«è¨­å®šã—ã¾ã—ãŸã€‚`!readoff` ã§åœæ­¢ã€‚")

@bot.event
async def on_message(message: discord.Message):
    await bot.process_commands(message)
    if not message.guild or message.author.bot:
        return

    # ã‚³ãƒãƒ³ãƒ‰ã¯èª­ã¾ãªã„ã‚ˆã†ã«ã™ã‚‹
    text = (message.content or "").strip()
    if text.startswith(("!", "ï¼")):
        return

    st = get_state(message.guild.id)
    if st["read_channel_id"] == message.channel.id and text:
        display = message.author.display_name if isinstance(message.author, discord.Member) else message.author.name
        to_say = f"{display}ï¼š{text}"
        await tts_play(message.guild, to_say, speaker_id=message.author.id)

        # â˜… ãƒ­ã‚°: èª­ã¿ä¸Šã’ãŸãƒ†ã‚­ã‚¹ãƒˆï¼ˆå…ƒå…¥åŠ›ï¼‰ãƒ»æŠ•ç¨¿è€…ãƒ»å…¥åŠ›æ™‚é–“
        # ã€Œèª­ã¿ä¸Šã’ãŸãƒ†ã‚­ã‚¹ãƒˆã€ã¯ message.contentï¼ˆTTSå‰ã®ç”Ÿãƒ†ã‚­ã‚¹ãƒˆï¼‰ã‚’æ®‹ã™ã®ãŒè¦ä»¶ã«å¿ å®Ÿ
        await log_tts_event(message, text)

@bot.command(name="ttsspeed", aliases=["èª­ã¿ä¸Šã’é€Ÿåº¦"])
async def ttsspeed(ctx: commands.Context, ratio: str = None):
    if not (ctx.author.guild_permissions.manage_guild or ctx.author.guild_permissions.administrator):
        return await ctx.reply("ã“ã®ã‚³ãƒãƒ³ãƒ‰ã¯ã‚µãƒ¼ãƒãƒ¼ç®¡ç†è€…ã®ã¿å®Ÿè¡Œã§ãã¾ã™ã€‚")
    if TTS_PROVIDER != "gtts":
        return await ctx.reply("ç¾åœ¨ã®èª­ã¿ä¸Šã’ã‚¨ãƒ³ã‚¸ãƒ³ã§ã¯ `ttsspeed` ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ (gTTS å°‚ç”¨æ©Ÿèƒ½)ã€‚")
    if not ratio:
        return await ctx.reply("ä½¿ã„æ–¹: `!ttsspeed 1.35`  ï¼ˆæ¨å¥¨: 0.6ã€œ2.0ï¼‰")

    try:
        r = float(ratio)
        if not (0.4 <= r <= 3.0):
            return await ctx.reply("å€¤ãŒåºƒã™ãã¾ã™ã€‚0.4ã€œ3.0 ã®ç¯„å›²ã§æŒ‡å®šã—ã¦ãã ã•ã„ï¼ˆæ¨å¥¨ 0.6ã€œ2.0ï¼‰ã€‚")
    except Exception:
        return await ctx.reply("æ•°å€¤ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚ä¾‹: `!ttsspeed 1.25`")

    st = get_state(ctx.guild.id)
    st["tts_base_tempo"] = r
    await ctx.reply(f"âœ… ã‚µãƒ¼ãƒãƒ¼åŸºæº–ã®èª­ã¿ä¸Šã’è©±é€Ÿã‚’ **{r:.2f}å€** ã«è¨­å®šã—ã¾ã—ãŸã€‚")

@bot.command(name="ttsvoice", aliases=["å£°è‰²"])
async def ttsvoice(ctx: commands.Context, member: discord.Member = None, semitones: str = None, tempo: str = None):
    if not (ctx.author.guild_permissions.manage_guild or ctx.author.guild_permissions.administrator):
        return await ctx.reply("ã“ã®ã‚³ãƒãƒ³ãƒ‰ã¯ã‚µãƒ¼ãƒãƒ¼ç®¡ç†è€…ã®ã¿å®Ÿè¡Œã§ãã¾ã™ã€‚")
    if TTS_PROVIDER != "gtts":
        return await ctx.reply("ç¾åœ¨ã®èª­ã¿ä¸Šã’ã‚¨ãƒ³ã‚¸ãƒ³ã§ã¯ `ttsvoice` ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ (gTTS å°‚ç”¨æ©Ÿèƒ½)ã€‚")

    if member is None or semitones is None:
        return await ctx.reply(
            "ä½¿ã„æ–¹:\n"
            "- `!ttsvoice @ãƒ¦ãƒ¼ã‚¶ãƒ¼ +3 1.15`  â€¦ åŠéŸ³+3 / ãƒ†ãƒ³ãƒ1.15å€\n"
            "- `!ttsvoice @ãƒ¦ãƒ¼ã‚¶ãƒ¼ reset`   â€¦ å€‹åˆ¥è¨­å®šã‚’è§£é™¤\n"
            "  â€»ãƒ†ãƒ³ãƒã¯çœç•¥å¯ï¼ˆçœç•¥æ™‚ã¯1.0ï¼‰"
        )

    st = get_state(ctx.guild.id)

    if semitones.lower() == "reset":
        st["tts_overrides"].pop(member.id, None)
        return await ctx.reply(f"ğŸ”„ {member.display_name} ã®å€‹åˆ¥å£°è¨­å®šã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸã€‚")

    # "+3" ã‚„ "-5" ãªã©ã«å¯¾å¿œ
    try:
        if semitones.startswith(("+", "-")):
            semi = float(semitones)
        else:
            semi = float(semitones)  # "3" ã‚‚è¨±å¯
    except Exception:
        return await ctx.reply("åŠéŸ³ã¯æ•°å€¤ã§æŒ‡å®šã—ã¦ãã ã•ã„ï¼ˆä¾‹: +3, -2, 0ï¼‰ã€‚")

    try:
        t = 1.0 if tempo is None else float(tempo)
        if not (0.5 <= (t * st["tts_base_tempo"]) <= 2.5):
            # å®ŸåŠ¹è©±é€Ÿï¼ˆã‚µãƒ¼ãƒãƒ¼åŸºæº–Ã—å€‹åˆ¥ï¼‰ã®å®‰å…¨ç¯„å›²ã‚’ã–ã£ãã‚Šãƒã‚§ãƒƒã‚¯
            pass
    except Exception:
        return await ctx.reply("ãƒ†ãƒ³ãƒã¯æ•°å€¤ã§æŒ‡å®šã—ã¦ãã ã•ã„ï¼ˆä¾‹: 1.10ï¼‰ã€‚")

    st["tts_overrides"][member.id] = {"semitones": semi, "tempo": t}
    await ctx.reply(
        f"âœ… {member.display_name} ã®å£°è‰²ã‚’è¨­å®šã—ã¾ã—ãŸï¼š åŠéŸ³ **{semi:+.1f}**, ãƒ†ãƒ³ãƒä¿‚æ•° **{t:.2f}**"
    )

@bot.command(name="ttsconfig", aliases=["èª­ã¿ä¸Šã’è¨­å®š"])
async def ttsconfig(ctx: commands.Context):
    st = get_state(ctx.guild.id)
    lines = [
        f"ğŸ”§ **TTSè¨­å®š**",
        f"- ã‚µãƒ¼ãƒãƒ¼åŸºæº–è©±é€Ÿ: x{st['tts_base_tempo']:.2f}",
        f"- å€‹åˆ¥è¨­å®šæ•°: {len(st['tts_overrides'])}",
    ]
    if st["tts_overrides"]:
        lines.append("- å€‹åˆ¥è¨­å®šï¼ˆæœ€å¤§10ä»¶è¡¨ç¤ºï¼‰:")
        for uid, ov in list(st["tts_overrides"].items())[:10]:
            m = ctx.guild.get_member(uid)
            name = m.display_name if m else f"User {uid}"
            lines.append(f"  â€¢ {name}: semitones={ov.get('semitones',0):+.1f}, tempo={ov.get('tempo',1.0):.2f}")
        if len(st["tts_overrides"]) > 10:
            lines.append(f"  â€¦ã»ã‹ {len(st['tts_overrides']) - 10} ä»¶")
    lines.append(f"- VOICEVOX ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè©±è€…ID: {st['tts_default_speaker']}")
    if st["tts_speakers"]:
        lines.append("- VOICEVOX å€‹åˆ¥è©±è€…ï¼ˆæœ€å¤§10ä»¶è¡¨ç¤ºï¼‰:")
        for uid, sid in list(st["tts_speakers"].items())[:10]:
            m = ctx.guild.get_member(uid)
            name = m.display_name if m else f"User {uid}"
            lines.append(f"  â€¢ {name}: speaker_id={sid}")
        if len(st["tts_speakers"]) > 10:
            lines.append(f"  â€¦ã»ã‹ {len(st['tts_speakers']) - 10} ä»¶")
    await ctx.reply("\n".join(lines))


@bot.command(name="ttsspeaker", aliases=["ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼", "speaker"])
async def ttsspeaker(ctx: commands.Context, *args):
    """VOICEVOX ã®è©±è€… ID ã‚’ç®¡ç†ã™ã‚‹ã‚³ãƒãƒ³ãƒ‰ã€‚"""
    if TTS_PROVIDER != "voicevox":
        return await ctx.reply("ç¾åœ¨ã®èª­ã¿ä¸Šã’ã‚¨ãƒ³ã‚¸ãƒ³ã§ã¯ VOICEVOX è©±è€…è¨­å®šã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")

    st = get_state(ctx.guild.id)

    if not args:
        current = st["tts_default_speaker"]
        count = len(st["tts_speakers"])
        return await ctx.reply(f"VOICEVOX ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè©±è€…IDã¯ {current}ã€å€‹åˆ¥è¨­å®šã¯ {count} ä»¶ã§ã™ã€‚")

    keyword = args[0].lower()

    if keyword == "export":
        if not (ctx.author.guild_permissions.manage_guild or ctx.author.guild_permissions.administrator):
            return await ctx.reply("ã“ã®æ“ä½œã¯ã‚µãƒ¼ãƒãƒ¼ç®¡ç†è€…ã®ã¿å®Ÿè¡Œã§ãã¾ã™ã€‚")
        payload = {
            "default_speaker": st["tts_default_speaker"],
            "user_speakers": {str(k): v for k, v in st["tts_speakers"].items()},
        }
        blob = json.dumps(payload, ensure_ascii=False, indent=2).encode("utf-8")
        fp = io.BytesIO(blob)
        fp.seek(0)
        return await ctx.reply(
            "VOICEVOX ã®è©±è€…è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã§ã™ã€‚",
            file=discord.File(fp, filename="voicevox_speakers.json"),
        )

    if keyword == "import":
        if not (ctx.author.guild_permissions.manage_guild or ctx.author.guild_permissions.administrator):
            return await ctx.reply("ã“ã®æ“ä½œã¯ã‚µãƒ¼ãƒãƒ¼ç®¡ç†è€…ã®ã¿å®Ÿè¡Œã§ãã¾ã™ã€‚")
        if not ctx.message.attachments:
            return await ctx.reply("JSON ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ·»ä»˜ã—ã¦ãã ã•ã„ã€‚")
        try:
            data = await ctx.message.attachments[0].read()
            payload = json.loads(data.decode("utf-8"))
        except Exception as exc:
            return await ctx.reply(f"JSON ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {exc!r}")

        if "default_speaker" in payload:
            try:
                st["tts_default_speaker"] = int(payload["default_speaker"])
            except Exception:
                return await ctx.reply("default_speaker ã¯æ•´æ•°ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")

        mapping = payload.get("user_speakers", {})
        new_map: dict[int, int] = {}
        try:
            for k, v in mapping.items():
                new_map[int(k)] = int(v)
        except Exception:
            return await ctx.reply("user_speakers å†…ã®ã‚­ãƒ¼ã¨å€¤ã¯æ•´æ•°ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")

        st["tts_speakers"] = new_map
        return await ctx.reply(f"VOICEVOX è©±è€…è¨­å®šã‚’ {len(new_map)} ä»¶èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")

    if keyword == "default":
        if not (ctx.author.guild_permissions.manage_guild or ctx.author.guild_permissions.administrator):
            return await ctx.reply("ã“ã®æ“ä½œã¯ã‚µãƒ¼ãƒãƒ¼ç®¡ç†è€…ã®ã¿å®Ÿè¡Œã§ãã¾ã™ã€‚")
        if len(args) < 2:
            return await ctx.reply("`!ttsspeaker default <speaker_id>` ã®å½¢å¼ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
        try:
            sid = int(args[1])
        except Exception:
            return await ctx.reply("speaker_id ã¯æ•´æ•°ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
        st["tts_default_speaker"] = sid
        return await ctx.reply(f"VOICEVOX ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè©±è€…IDã‚’ {sid} ã«è¨­å®šã—ã¾ã—ãŸã€‚")

    # å€‹åˆ¥ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨­å®š
    member = ctx.message.mentions[0] if ctx.message.mentions else None
    if member is None:
        try:
            uid = int(args[0])
            member = ctx.guild.get_member(uid)
            if member is None:
                member = await ctx.guild.fetch_member(uid)
        except Exception:
            member = None
    if member is None or (member != ctx.author and not (ctx.author.guild_permissions.manage_guild or ctx.author.guild_permissions.administrator)):
        # ç®¡ç†æ¨©é™ãŒç„¡ã„å ´åˆã¯è‡ªèº«ã®ã¿è¨­å®šå¯èƒ½
        member = ctx.author

    if member is None:
        return await ctx.reply("ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’ç‰¹å®šã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã¾ãŸã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼IDã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")

    if len(args) < 2:
        current = st["tts_speakers"].get(member.id)
        return await ctx.reply(f"{member.display_name} ã®è©±è€…IDã¯ {current if current is not None else 'æœªè¨­å®š'} ã§ã™ã€‚")

    value = args[1].lower()
    if value in ("reset", "clear"):
        st["tts_speakers"].pop(member.id, None)
        return await ctx.reply(f"{member.display_name} ã® VOICEVOX è©±è€…è¨­å®šã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")

    try:
        sid = int(value)
    except Exception:
        return await ctx.reply("speaker_id ã¯æ•´æ•°ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")

    st["tts_speakers"][member.id] = sid
    if member == ctx.author:
        return await ctx.reply(f"ã‚ãªãŸã® VOICEVOX è©±è€…IDã‚’ {sid} ã«è¨­å®šã—ã¾ã—ãŸã€‚")
    return await ctx.reply(f"{member.display_name} ã® VOICEVOX è©±è€…IDã‚’ {sid} ã«è¨­å®šã—ã¾ã—ãŸã€‚")


@bot.command(name="sttcolor", aliases=["å­—å¹•è‰²", "color"])
async def sttcolor(ctx: commands.Context, *args):
    """å­—å¹•ã‚«ãƒ©ãƒ¼è¨­å®šã‚’ç®¡ç†ã™ã‚‹ã€‚"""

    st = get_state(ctx.guild.id)

    if not args:
        count = len(st["stt_color_overrides"])
        example = ", ".join(
            f"{idx}:{hex(color)[2:]}" for idx, color in enumerate(STT_COLOR_PALETTE)
        )
        return await ctx.reply(
            "å­—å¹•ã‚«ãƒ©ãƒ¼è¨­å®šã®æ¦‚è¦ã§ã™ã€‚\n"
            f"- å€‹åˆ¥è¨­å®šæ•°: {count} ä»¶\n"
            f"- ã‚«ãƒ©ãƒ¼ãƒ‘ãƒ¬ãƒƒãƒˆ (0-15): {example}"
        )

    keyword = args[0].lower()

    if keyword == "export":
        if not (ctx.author.guild_permissions.manage_guild or ctx.author.guild_permissions.administrator):
            return await ctx.reply("ã“ã®æ“ä½œã¯ã‚µãƒ¼ãƒãƒ¼ç®¡ç†è€…ã®ã¿å®Ÿè¡Œã§ãã¾ã™ã€‚")
        payload = {
            "user_colors": {str(k): v for k, v in st["stt_color_overrides"].items()}
        }
        blob = json.dumps(payload, ensure_ascii=False, indent=2).encode("utf-8")
        fp = io.BytesIO(blob)
        fp.seek(0)
        return await ctx.reply(
            "å­—å¹•ã‚«ãƒ©ãƒ¼è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã§ã™ã€‚",
            file=discord.File(fp, filename="stt_colors.json"),
        )

    if keyword == "import":
        if not (ctx.author.guild_permissions.manage_guild or ctx.author.guild_permissions.administrator):
            return await ctx.reply("ã“ã®æ“ä½œã¯ã‚µãƒ¼ãƒãƒ¼ç®¡ç†è€…ã®ã¿å®Ÿè¡Œã§ãã¾ã™ã€‚")
        if not ctx.message.attachments:
            return await ctx.reply("JSON ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ·»ä»˜ã—ã¦ãã ã•ã„ã€‚")
        try:
            data = await ctx.message.attachments[0].read()
            payload = json.loads(data.decode("utf-8"))
        except Exception as exc:
            return await ctx.reply(f"JSON ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {exc!r}")

        mapping = payload.get("user_colors", {})
        new_map: dict[int, int] = {}
        try:
            for k, v in mapping.items():
                idx = int(v)
                if 0 <= idx < len(STT_COLOR_PALETTE):
                    new_map[int(k)] = idx
                else:
                    return await ctx.reply("color index ã¯ 0-15 ã®ç¯„å›²ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
        except Exception:
            return await ctx.reply("user_colors å†…ã®ã‚­ãƒ¼ã¨å€¤ã¯æ•´æ•°ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")

        st["stt_color_overrides"] = new_map
        return await ctx.reply(f"å­—å¹•ã‚«ãƒ©ãƒ¼è¨­å®šã‚’ {len(new_map)} ä»¶èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")

    member = ctx.message.mentions[0] if ctx.message.mentions else None
    if member is None:
        try:
            uid = int(args[0])
            member = ctx.guild.get_member(uid)
            if member is None:
                member = await ctx.guild.fetch_member(uid)
        except Exception:
            member = None
    if member is None or (member != ctx.author and not (ctx.author.guild_permissions.manage_guild or ctx.author.guild_permissions.administrator)):
        member = ctx.author

    if member is None:
        return await ctx.reply("ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’ç‰¹å®šã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã¾ãŸã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼IDã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")

    if len(args) < 2:
        current = st["stt_color_overrides"].get(member.id)
        return await ctx.reply(
            f"{member.display_name} ã®å­—å¹•ã‚«ãƒ©ãƒ¼ã¯ {current if current is not None else 'è‡ªå‹•å‰²ã‚Šå½“ã¦'} ã§ã™ã€‚"
        )

    value = args[1].lower()
    if value in ("reset", "clear"):
        st["stt_color_overrides"].pop(member.id, None)
        return await ctx.reply(f"{member.display_name} ã®å­—å¹•ã‚«ãƒ©ãƒ¼è¨­å®šã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")

    try:
        idx = int(value)
    except Exception:
        return await ctx.reply("ã‚«ãƒ©ãƒ¼ç•ªå·ã¯ 0-15 ã®æ•´æ•°ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")

    if not (0 <= idx < len(STT_COLOR_PALETTE)):
        return await ctx.reply("ã‚«ãƒ©ãƒ¼ç•ªå·ã¯ 0-15 ã®ç¯„å›²ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")

    st["stt_color_overrides"][member.id] = idx
    if member == ctx.author:
        return await ctx.reply(f"ã‚ãªãŸã®å­—å¹•ã‚«ãƒ©ãƒ¼ã‚’ {idx} ã«è¨­å®šã—ã¾ã—ãŸã€‚")
    return await ctx.reply(f"{member.display_name} ã®å­—å¹•ã‚«ãƒ©ãƒ¼ã‚’ {idx} ã«è¨­å®šã—ã¾ã—ãŸã€‚")


@bot.command(name="voicevoxstyles", aliases=["voxstyles", "voxlist"])
async def voicevoxstyles(ctx: commands.Context):
    """VOICEVOX ã®è©±è€…IDã¨ã‚¹ã‚¿ã‚¤ãƒ«ä¸€è¦§ã‚’è¡¨ç¤ºã™ã‚‹ã€‚"""
    if TTS_PROVIDER != "voicevox":
        return await ctx.reply("ç¾åœ¨ã®èª­ã¿ä¸Šã’ã‚¨ãƒ³ã‚¸ãƒ³ã¯ VOICEVOX ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
    try:
        resp = requests.get(f"{VOICEVOX_BASE_URL}/speakers", timeout=VOICEVOX_TIMEOUT)
        resp.raise_for_status()
        payload = resp.json()
    except Exception as exc:
        return await ctx.reply(f"VOICEVOX ã®ã‚¹ã‚¿ã‚¤ãƒ«å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {exc!r}")

    lines: list[str] = []
    for speaker in payload or []:
        base_name = speaker.get("name", "unknown")
        for style in speaker.get("styles", []):
            sid = style.get("id")
            style_name = style.get("name", "default")
            if sid is None:
                continue
            lines.append(f"{sid:>4}: {base_name} / {style_name}")

    if not lines:
        return await ctx.reply("ã‚¹ã‚¿ã‚¤ãƒ«æƒ…å ±ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

    chunk = []
    header = "VOICEVOX è©±è€…IDã¨ã‚¹ã‚¿ã‚¤ãƒ«ä¸€è¦§"
    for line in lines:
        chunk.append(line)
        if len("\n".join(chunk)) > 1700:
            text = "\n".join(chunk[:-1])
            await ctx.reply(f"{header}\n```\n{text}\n```")
            header = ""
            chunk = [chunk[-1]]
    if chunk:
        text = "\n".join(chunk)
        await ctx.reply((f"{header}\n" if header else "") + f"```\n{text}\n```")


@bot.command(name="sttpalette", aliases=["colorpalette", "palette"])
async def sttpalette(ctx: commands.Context):
    """å­—å¹•ã‚«ãƒ©ãƒ¼ã®ãƒ‘ãƒ¬ãƒƒãƒˆç•ªå·ã¨ã‚«ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰ã‚’è¡¨ç¤ºã™ã‚‹ã€‚"""
    embeds: list[discord.Embed] = []
    for idx, color in enumerate(STT_COLOR_PALETTE):
        embed = discord.Embed(
            title=f"ãƒ‘ãƒ¬ãƒƒãƒˆ {idx}",
            description=f"ã‚«ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰: `#{color:06X}`\nã“ã®è‰²ã§å­—å¹•ã‚’è¨­å®šã™ã‚‹ã«ã¯ `!sttcolor @ãƒ¦ãƒ¼ã‚¶ãƒ¼ {idx}`" ,
            color=color,
        )
        embed.set_footer(text="å­—å¹•ã‚«ãƒ©ãƒ¼ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã§ã™ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ãŒè©²å½“è‰²ã«ãªã‚Šã¾ã™ã€‚")
        embeds.append(embed)

    if not embeds:
        return await ctx.reply("ãƒ‘ãƒ¬ãƒƒãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

    for i in range(0, len(embeds), 10):
        await ctx.reply(embeds=embeds[i:i+10])


@bot.command(name="voxdict", aliases=["è¾æ›¸ç®¡ç†"])
async def voxdict(ctx: commands.Context, action: str | None = None, *args):
    """VOICEVOX ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼è¾æ›¸ã‚’ç®¡ç†ã™ã‚‹ã€‚"""
    if TTS_PROVIDER != "voicevox":
        return await ctx.reply("ç¾åœ¨ã®èª­ã¿ä¸Šã’ã‚¨ãƒ³ã‚¸ãƒ³ã§ã¯ VOICEVOX è¾æ›¸ã‚’ç®¡ç†ã§ãã¾ã›ã‚“ã€‚")

    is_admin = ctx.author.guild_permissions.manage_guild or ctx.author.guild_permissions.administrator

    if not action:
        return await ctx.reply(
            "ä½¿ã„æ–¹: `!voxdict export` / `!voxdict import` (JSONæ·»ä»˜) / "
            "`!voxdict add <è¡¨å±¤å½¢> <ç™ºéŸ³> [ã‚¢ã‚¯ã‚»ãƒ³ãƒˆç•ªå·]`"
        )

    key = action.lower()

    if key == "export":
        if not is_admin:
            return await ctx.reply("è¾æ›¸ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã¯ã‚µãƒ¼ãƒãƒ¼ç®¡ç†è€…ã®ã¿å®Ÿè¡Œã§ãã¾ã™ã€‚")
        try:
            items = await _voicevox_list_dictionary()
        except Exception as exc:
            return await ctx.reply(f"è¾æ›¸å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {exc!r}")

        payload = [
            {
                "surface": item.get("surface"),
                "pronunciation": item.get("pronunciation"),
                "accent_type": item.get("accent_type"),
                "word_type": item.get("word_type"),
            }
            for item in items
        ]
        data = json.dumps(payload, ensure_ascii=False, indent=2).encode("utf-8")
        fp = io.BytesIO(data)
        fp.seek(0)
        return await ctx.reply("VOICEVOX è¾æ›¸ãƒ•ã‚¡ã‚¤ãƒ«ã§ã™ã€‚", file=discord.File(fp, filename="voicevox_dictionary.json"))

    if key == "import":
        if not is_admin:
            return await ctx.reply("è¾æ›¸ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã¯ã‚µãƒ¼ãƒãƒ¼ç®¡ç†è€…ã®ã¿å®Ÿè¡Œã§ãã¾ã™ã€‚")
        if not ctx.message.attachments:
            return await ctx.reply("è¾æ›¸JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ·»ä»˜ã—ã¦ãã ã•ã„ã€‚")
        try:
            blob = await ctx.message.attachments[0].read()
            entries = json.loads(blob.decode("utf-8"))
        except Exception as exc:
            return await ctx.reply(f"JSON ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {exc!r}")

        added = 0
        errors = 0
        last_error = None
        for entry in entries:
            if not isinstance(entry, dict):
                continue
            surface = entry.get("surface")
            pron = entry.get("pronunciation")
            accent = entry.get("accent_type")
            wtype = entry.get("word_type", "PROPER_NOUN")
            if not surface or not pron:
                continue
            try:
                await _voicevox_add_dictionary_word(surface, pron, accent, wtype)
                added += 1
            except Exception as exc:
                errors += 1
                last_error = str(exc)
                print("[VOICEVOX] import error:", repr(exc))
        message = f"è¾æ›¸ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã—ãŸã€‚è¿½åŠ  {added} ä»¶ / å¤±æ•— {errors} ä»¶ã€‚"
        if last_error:
            message += f"\nç›´è¿‘ã®ã‚¨ãƒ©ãƒ¼: {last_error}"
        return await ctx.reply(message)

    if key == "add":
        if len(args) < 2:
            return await ctx.reply("`!voxdict add <è¡¨å±¤å½¢> <ç™ºéŸ³> [ã‚¢ã‚¯ã‚»ãƒ³ãƒˆç•ªå·]` ã®å½¢å¼ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
        surface = args[0]
        pronunciation = args[1]
        accent = None
        if len(args) >= 3:
            try:
                accent = int(args[2])
            except Exception:
                return await ctx.reply("ã‚¢ã‚¯ã‚»ãƒ³ãƒˆç•ªå·ã¯æ•´æ•°ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
        try:
            await _voicevox_add_dictionary_word(surface, pronunciation, accent)
            return await ctx.reply(f"è¾æ›¸ã« `{surface}` ({pronunciation}) ã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚")
        except Exception as exc:
            return await ctx.reply(f"è¾æ›¸ã¸ã®è¿½åŠ ã«å¤±æ•—ã—ã¾ã—ãŸ: {exc!r}")

    return await ctx.reply("æœªçŸ¥ã®æ“ä½œã§ã™ã€‚`export` / `import` / `add` ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")


@bot.command(name="logs", aliases=["ãƒ­ã‚°å–å¾—", "getlogs"])
async def download_logs(ctx: commands.Context):
    """éŸ³å£°é–¢é€£ãƒ­ã‚°ï¼ˆTTS/STTï¼‰ã‚’å–å¾—ã—ã¦é€ä¿¡ã™ã‚‹ã€‚"""
    files: list[discord.File] = []
    async with _log_lock:
        for path in (TTS_LOG_PATH, STT_LOG_PATH, STT_METRICS_PATH, CCFO_LOG_PATH):
            if path.exists():
                data = path.read_bytes()
                buff = io.BytesIO(data)
                buff.seek(0)
                files.append(discord.File(buff, filename=path.name))

    if not files:
        return await ctx.reply("ã¾ã ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")

    await ctx.reply("æœ€æ–°ã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã§ã™ã€‚", files=files)

@bot.command(name="sttset")
async def sttset(ctx, key: str=None, value: str=None):
    """
      !sttset vad 0.008
      !sttset vaddb -46
      !sttset mindur 0.4
      !sttset merge 14
      !sttset mergeauto on/off
      !sttset lang ja
      !sttset thread on
      !sttset denoise on/off
      !sttset denoisemode arnndn
      !sttset sttmodel gpt-4o-mini-transcribe
      !sttset sttmodel2 gpt-4o-transcribe
    """
    st = get_state(ctx.guild.id)
    if not key:
        return await ctx.reply(
            (
                "è¨­å®š: mode={stt_mode} window={record_window}s vad={vad_rms} vaddb={vad_db} "
                "mindur={min_dur}s merge={merge_window}s mergeauto={merge_auto} lang={lang} thread={use_thread} "
                "vadlevel={vad_aggressiveness} silence={vad_silence_ms}ms pre={vad_pre_ms}ms post={vad_post_ms}ms overlap={vad_overlap_ms}ms "
                "denoise={denoise_enable} dmode={denoise_mode} hp={denoise_highpass} lp={denoise_lowpass} strength={denoise_strength} gain={denoise_gain} "
                "model={stt_primary_model} fallback={stt_fallback_model}"
            ).format(**st)
        )

    try:
        k = key.lower()
        if k == "vad":
            st["vad_rms"] = float(value)
        elif k in ("vaddb","db"):
            st["vad_db"] = float(value)
        elif k in ("mindur","min"):
            st["min_dur"] = float(value)
        elif k in ("merge","mw"):
            st["merge_window"] = float(value)
        elif k in ("mergeauto","ma"):
            st["merge_auto"] = (value.lower() in ("on","true","1","yes","y"))
        elif k == "lang":
            st["lang"] = "ja"
            if value and value.lower() not in ("ja", "japanese", "æ—¥æœ¬èª", "jp"):
                return await ctx.reply("è¨€èªã¯æ—¥æœ¬èªå›ºå®šã§ã™ï¼ˆlang=jaï¼‰ã€‚")
        elif k in ("thread","th"):
            st["use_thread"] = (value.lower() in ("on","true","1","yes","y"))
            st["caption_dest_id"] = None
        elif k in ("mode", "sttmode"):
            lv = value.lower()
            if lv not in ("vad", "fixed"):
                return await ctx.reply("mode ã¯ `vad` ã¾ãŸã¯ `fixed` ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
            st["stt_mode"] = lv
        elif k in ("window", "win"):
            win = int(value)
            if not (3 <= win <= 60):
                return await ctx.reply("window ã¯ 3ã€œ60 ã®æ•´æ•°ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
            st["record_window"] = win
        elif k in ("vadlevel", "vadmode", "vadaggr"):
            lvl = int(value)
            if not (0 <= lvl <= 3):
                return await ctx.reply("vadlevel ã¯ 0ã€œ3 ã®æ•´æ•°ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
            st["vad_aggressiveness"] = lvl
        elif k in ("vadsilence", "silence"):
            st["vad_silence_ms"] = max(120, min(2000, int(value)))
        elif k in ("vadpre", "pre"):
            st["vad_pre_ms"] = max(0, min(1000, int(value)))
        elif k in ("vadpost", "post"):
            st["vad_post_ms"] = max(0, min(1500, int(value)))
        elif k in ("vadoverlap", "overlap"):
            st["vad_overlap_ms"] = max(0, min(1000, int(value)))
        elif k in ("denoise", "dn"):
            st["denoise_enable"] = value.lower() in ("on", "true", "1", "yes", "y")
            st["denoise_ffmpeg_failed"] = False
        elif k in ("denoisemode", "dnmode"):
            lv = value.lower()
            if lv not in ("arnndn", "afftdn"):
                return await ctx.reply("denoisemode ã¯ `arnndn` ã¾ãŸã¯ `afftdn` ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
            st["denoise_mode"] = lv
            st["denoise_ffmpeg_failed"] = False
        elif k in ("denoisemodel", "dnmodel"):
            st["denoise_model"] = value
            st["denoise_ffmpeg_failed"] = False
        elif k in ("denoisehp", "dnhp"):
            st["denoise_highpass"] = max(0, min(2000, int(value)))
            st["denoise_ffmpeg_failed"] = False
        elif k in ("denoiselp", "dnlp"):
            st["denoise_lowpass"] = max(1000, min(20000, int(value)))
            st["denoise_ffmpeg_failed"] = False
        elif k in ("denoisestr", "dnstr", "dnstrength"):
            st["denoise_strength"] = max(0.0, min(30.0, float(value)))
            st["denoise_ffmpeg_failed"] = False
        elif k in ("denoisegain", "dngain"):
            st["denoise_gain"] = max(0.0, min(30.0, float(value)))
            st["denoise_ffmpeg_failed"] = False
        elif k in ("denoisecomp", "dncomp"):
            st["denoise_compand"] = value
            st["denoise_ffmpeg_failed"] = False
        elif k in ("sttmodel", "model", "primarymodel"):
            if not value:
                return await ctx.reply("ãƒ¢ãƒ‡ãƒ«åã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚ä¾‹: gpt-4o-mini-transcribe")
            st["stt_primary_model"] = value.strip()
        elif k in ("sttmodel2", "fallback", "secondarymodel"):
            if not value:
                return await ctx.reply("ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«åã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚ä¾‹: gpt-4o-transcribe")
            st["stt_fallback_model"] = value.strip()
        else:
            return await ctx.reply(
                "æœªçŸ¥ã®ã‚­ãƒ¼: vad / vaddb / mindur / merge / mergeauto / lang / thread / "
                "mode / window / vadlevel / vadsilence / vadpre / vadpost / vadoverlap / "
                "denoise / denoisemode / denoisemodel / denoisehp / denoiselp / denoisestr / denoisegain / denoisecomp / sttmodel / sttmodel2"
            )
    except Exception as e:
        return await ctx.reply(f"è¨­å®šå¤±æ•—: {e!r}")

    await ctx.reply(
        (
            "OK: mode={stt_mode} window={record_window}s vad={vad_rms} vaddb={vad_db} "
            "mindur={min_dur}s merge={merge_window}s mergeauto={merge_auto} lang={lang} thread={use_thread} "
            "vadlevel={vad_aggressiveness} silence={vad_silence_ms}ms pre={vad_pre_ms}ms post={vad_post_ms}ms overlap={vad_overlap_ms}ms "
            "denoise={denoise_enable} dmode={denoise_mode} hp={denoise_highpass} lp={denoise_lowpass} strength={denoise_strength} gain={denoise_gain} "
            "model={stt_primary_model} fallback={stt_fallback_model}"
        ).format(**st)
    )


async def stt_worker(guild_id: int, channel_id: int):
    guild_obj = bot.get_guild(guild_id)
    if not guild_obj:
        return
    print("[STT] worker start", guild_id, channel_id)
    st = get_state(guild_id)
    vad_streams: dict[int, _VadUserStream] = {}
    vad_last_seen: dict[int, float] = {}
    warned_vad_missing = False

    try:
        while True:
            vc = guild_obj.voice_client
            if not vc or not vc.is_connected():
                print("[STT] no voice connection; retry")
                await asyncio.sleep(1.0)
                continue

            # æŠ•ç¨¿å…ˆè§£æ±º
            base = await resolve_message_channel(channel_id, guild_id)
            if base is None:
                print("[STT] message channel not found; retry")
                await asyncio.sleep(2.0)
                continue

            # ã‚¹ãƒ¬ãƒƒãƒ‰ï¼ˆå¿…è¦ãªã‚‰ï¼‰
            dest = base
            if st["use_thread"]:
                try:
                    if st.get("caption_dest_id"):
                        t = await resolve_message_channel(st["caption_dest_id"], guild_id)
                        if isinstance(t, discord.Thread):
                            dest = t
                        else:
                            st["caption_dest_id"] = None
                    if st.get("caption_dest_id") is None and isinstance(base, discord.TextChannel):
                        th = await base.create_thread(name="ğŸ¤å­—å¹•", auto_archive_duration=60)
                        st["caption_dest_id"] = th.id
                        dest = th
                except Exception as e:
                    print("[STT] thread create/resolve failed:", repr(e))
                    dest = base

            # ===== éŒ²éŸ³ 1 ã‚µã‚¤ã‚¯ãƒ« =====
            async with st["rec_lock"]:  # â˜… åŒæ™‚å®Ÿè¡Œã‚’ãƒ–ãƒ­ãƒƒã‚¯
                # ã‚‚ã—å–ã‚Šæ®‹ã—ãŒã‚ã‚Œã°æ­¢ã‚ã‚‹
                await ensure_stopped(vc, "before start")

                sink = discord.sinks.WaveSink()
                done = asyncio.Event()
                captured: list[tuple[int, object, bytes]] = []

                def _collect_filelike(fileobj) -> bytes:
                    if isinstance(fileobj, (str, os.PathLike)):
                        with open(fileobj, "rb") as rf:
                            return rf.read()
                    try:
                        fileobj.seek(0)
                    except Exception:
                        pass
                    return fileobj.read() if hasattr(fileobj, "read") else bytes(fileobj)

                async def finished_callback(sink, *args):
                    try:
                        # ãƒ‡ãƒãƒƒã‚°ï¼šã©ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ¥ãŸã‹
                        print("[STT] users in window:", list(sink.audio_data.keys()))
                        for user_id, data in sink.audio_data.items():
                            uid = int(user_id)
                            f = data.file
                            # ç©ºWAVã¯å¼¾ã
                            size = None
                            if isinstance(f, (str, os.PathLike)):
                                try: size = os.path.getsize(f)
                                except: size = None
                            else:
                                try:
                                    p = f.tell(); f.seek(0, os.SEEK_END)
                                    size = f.tell(); f.seek(p)
                                except: size = None
                            if size is not None and size <= 44:
                                continue
                            buf = _collect_filelike(f)
                            captured.append((uid, data, buf))
                    finally:
                        done.set()

                # start_recordingï¼ˆå–ã‚Šæ®‹ã—ãŒã‚ã‚‹ã¨ä¾‹å¤–ã«ãªã‚‹ï¼‰
                try:
                    print(f"[STT] start_recording() rec={getattr(vc,'recording',None)}")
                    vc.start_recording(sink, finished_callback)
                except Exception as e:
                    print("[STT] start_recording failed:", repr(e))
                    # ã™ã§ã«éŒ²éŸ³ä¸­ãªã‚‰æ­¢ã‚ã¦æ¬¡ãƒ«ãƒ¼ãƒ—
                    if "Already recording" in str(e):
                        await ensure_stopped(vc, "after start fail")
                        await asyncio.sleep(0.3)
                        continue
                    await asyncio.sleep(1.0)
                    continue

                window = float(st.get("record_window", DEFAULT_WINDOW))
                if window < 1.0:
                    window = 1.0
                await asyncio.sleep(window)

                # åœæ­¢ï¼ˆåŒæœŸï¼‰
                try:
                    print("[STT] stop_recording()")
                    vc.stop_recording()
                except Exception as e:
                    print("[STT] stop_recording failed:", repr(e))

                await done.wait()
                await ensure_stopped(vc, "after stop")  # å¿µã®ãŸã‚

            # ã“ã“ã¾ã§ãŒ1ã‚µã‚¤ã‚¯ãƒ«ï¼ˆãƒ­ãƒƒã‚¯è§£æ”¾ï¼‰

            mode = st.get("stt_mode", "vad")
            use_vad = mode == "vad" and webrtcvad is not None
            now_ts = time.time()

            if mode == "vad" and webrtcvad is None and not warned_vad_missing:
                print("[STT] webrtcvad is not available; falling back to fixed segmentation")
                warned_vad_missing = True

            jobs: list[T.Awaitable] = []
            if use_vad:
                captured_users: set[int] = set()
                for (uid, data, buf) in captured:
                    captured_users.add(uid)
                    stream = vad_streams.get(uid)
                    if stream is None:
                        stream = _VadUserStream()
                        vad_streams[uid] = stream
                    vad_last_seen[uid] = now_ts
                    name = await resolve_display_name(guild_obj, uid, data)
                    segments = stream.feed(buf, st)
                    for segment_wav in segments:
                        jobs.append(transcribe_and_post_from_bytes(guild_id, uid, name, segment_wav, dest))

                silence_sec = (st.get("vad_silence_ms", 450) + st.get("vad_post_ms", 400)) / 1000.0
                idle_threshold = max(st.get("record_window", DEFAULT_WINDOW), silence_sec + 0.5)

                for uid in list(vad_streams.keys()):
                    if uid in captured_users:
                        continue
                    last_seen = vad_last_seen.get(uid, 0.0)
                    if (now_ts - last_seen) > idle_threshold:
                        name = await resolve_display_name(guild_obj, uid, None)
                        drained = vad_streams[uid].drain()
                        if drained:
                            for segment_wav in drained:
                                jobs.append(transcribe_and_post_from_bytes(guild_id, uid, name, segment_wav, dest))
                        vad_streams.pop(uid, None)
                        vad_last_seen.pop(uid, None)

                if jobs:
                    await asyncio.gather(*jobs, return_exceptions=True)
                elif not captured:
                    print("[STT] no audio captured in this window (VAD mode)")
                    await asyncio.sleep(0.3)
                continue

            if not captured:
                print("[STT] no audio captured in this window")
                await asyncio.sleep(0.3)
                continue

            # VADã‚’é€šã•ãªã„å›ºå®šåŒºåˆ‡ã‚Šãƒ¢ãƒ¼ãƒ‰
            if vad_streams:
                for uid, stream in list(vad_streams.items()):
                    name = await resolve_display_name(guild_obj, uid, None)
                    drained = stream.drain()
                    for segment_wav in drained:
                        jobs.append(transcribe_and_post_from_bytes(guild_id, uid, name, segment_wav, dest))
                vad_streams.clear()
                vad_last_seen.clear()

            for (uid, data, buf) in captured:
                name = await resolve_display_name(guild_obj, uid, data)
                jobs.append(transcribe_and_post_from_bytes(guild_id, uid, name, buf, dest))
            await asyncio.gather(*jobs, return_exceptions=True)

    except asyncio.CancelledError:
        print("[STT] worker cancelled", guild_id)
        # ã‚­ãƒ£ãƒ³ã‚»ãƒ«æ™‚ã‚‚éŒ²éŸ³æ®‹ã£ã¦ãŸã‚‰æ­¢ã‚ã‚‹
        vc = guild_obj.voice_client
        if vc and vc.is_connected():
            await ensure_stopped(vc, "on cancel")
    except Exception as e:
        print("[STT] worker crashed:", repr(e))
        traceback.print_exc()
        # ã‚¯ãƒ©ãƒƒã‚·ãƒ¥æ™‚ã‚‚å®‰å…¨å¼
        vc = guild_obj.voice_client
        if vc and vc.is_connected():
            await ensure_stopped(vc, "on crash")
    finally:
        if vad_streams:
            flush_dest = await resolve_message_channel(channel_id, guild_id)
            if flush_dest:
                flush_jobs = []
                for uid, stream in list(vad_streams.items()):
                    drained = stream.drain()
                    if not drained:
                        continue
                    name = await resolve_display_name(guild_obj, uid, None)
                    for segment_wav in drained:
                        flush_jobs.append(transcribe_and_post_from_bytes(guild_id, uid, name, segment_wav, flush_dest))
                if flush_jobs:
                    await asyncio.gather(*flush_jobs, return_exceptions=True)
        print("[STT] worker end", guild_id)

@bot.command(name="intentcheck")
async def intentcheck(ctx):
    # ã‚³ãƒ¼ãƒ‰å´ã®æ„å›³ï¼ˆboolï¼‰
    code_flag = bot.intents.members

    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥/ãƒ•ã‚§ãƒƒãƒã®å®ŸæŒ™å‹•
    cache_hit = ctx.guild.get_member(ctx.author.id) is not None
    try:
        fetched = await ctx.guild.fetch_member(ctx.author.id)
        fetch_ok = fetched is not None
        err = None
    except Exception as e:
        fetch_ok = False
        err = repr(e)

    await ctx.reply(
        "ğŸ§ª intents.members(check)\n"
        f"- code_flag: {code_flag}\n"
        f"- cache_has_author: {cache_hit}\n"
        f"- fetch_member_ok: {fetch_ok}\n"
        f"- fetch_error: {err}"
    )

async def record_once(guild: discord.Guild, seconds: int):
    """
    seconds ç§’ã ã‘éŒ²éŸ³ã—ã¦ã€[(username, bytes)] ã‚’è¿”ã™ã€‚
    """
    vc: discord.VoiceClient = guild.voice_client
    if not vc or not vc.is_connected():
        return []

    sink = discord.sinks.WaveSink()
    done = asyncio.Event()
    results: list[tuple[str, bytes]] = []

    async def finished_callback(sink, *args):
        try:
            for user_id, data in sink.audio_data.items():
                name = await resolve_display_name(guild, int(user_id), data)
                fileobj = data.file

                # bytes ã¸è½ã¨ã™
                if isinstance(fileobj, (str, os.PathLike)):
                    with open(fileobj, "rb") as rf:
                        buf = rf.read()
                else:
                    try: fileobj.seek(0)
                    except: pass
                    buf = fileobj.read() if hasattr(fileobj, "read") else bytes(fileobj)

                results.append((name, buf))
        finally:
            try: vc.stop_recording()
            except: pass
            done.set()

    try:
        vc.start_recording(sink, finished_callback)
    except Exception as e:
        print("[STT] start_recording failed:", repr(e))
        return []

    await asyncio.sleep(seconds)
    try: 
        vc.stop_recording()
    except: 
        pass
    await done.wait()
    return results

async def transcribe_and_post_from_bytes(guild_id: int, user_id: int, username: str, buf: bytes, channel):
    if not openai:
        print("[STT] OpenAI client is None"); return
    st = get_state(guild_id)

    try:
        processed = await _maybe_denoise_wav(buf, st)
        if processed:
            buf = processed
    except Exception:
        traceback.print_exc()

    # --- VADï¼ˆç„¡éŸ³ã‚¹ã‚­ãƒƒãƒ—ã®æ¡ä»¶ã‚’ç·©ã‚ã‚‹ï¼‰---
    dur = None
    rms = None
    db = None
    try:
        dur, rms = wav_stats(buf)
        # WAVãƒ¡ã‚¿ä¸æ•´åˆå¯¾ç­–ï¼šæ¦‚ç®—é•·ï¼ˆ48kHz/16bit/2ch â‰’ 192kB/sï¼‰
        if (dur == 0.0 or dur is None) and len(buf) > 44:
            dur = len(buf) / 192000.0
        db = _dbfs_from_rms(rms or 0.0)
        print(f"[STT] segment stats: dur={dur:.2f}s rms={rms:.4f} ({db:.1f} dBFS)")

        # ã€ŒçŸ­ã„ ã‹ã¤ å°ã•ã„ ã‹ã¤ é™ã‹ã€ãªã‚‰ã‚¹ã‚­ãƒƒãƒ—ï¼ˆANDï¼‰
        should_skip = (dur < st["min_dur"]) and (rms < st["vad_rms"]) and (db < st["vad_db"])
        if should_skip:
            print("[STT] skip by VAD")
            return
    except Exception:
        traceback.print_exc()

    # --- STT ãƒ¢ãƒ‡ãƒ«é©ç”¨ ---
    models_to_try: list[str] = []
    primary_model = (st.get("stt_primary_model") or DEFAULT_PRIMARY_STT_MODEL).strip()
    fallback_model = (st.get("stt_fallback_model") or DEFAULT_FALLBACK_STT_MODEL).strip()

    def _append_model(name: str):
        n = (name or "").strip()
        if n and n not in models_to_try:
            models_to_try.append(n)

    _append_model(primary_model)
    _append_model(fallback_model)
    _append_model("whisper-1")  # æœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯

    text = ""
    used_model = None
    used_metrics: dict[str, float | int | None] = {}
    last_error: Exception | None = None

    for idx, model_name in enumerate(models_to_try):
        try:
            bio = io.BytesIO(buf)
            bio.name = "audio.wav"
            resp = openai.audio.transcriptions.create(
                file=bio,
                model=model_name,
                language="ja",
            )
            candidate = (getattr(resp, "text", "") or "").strip()
            metrics_candidate, retry_flag = _evaluate_transcription_response(resp, candidate, dur)
            print(f"[STT] {model_name} result: {candidate!r} retry={retry_flag}")
            if candidate:
                text = candidate
                used_model = model_name
                used_metrics = metrics_candidate
                if not retry_flag or idx == len(models_to_try) - 1:
                    break
                else:
                    print(f"[STT] retry requested, moving to next model after {model_name}")
                    continue
        except Exception as exc:
            last_error = exc
            print(f"[STT] transcription via {model_name} failed:", repr(exc))
            traceback.print_exc()

    if not text:
        if last_error:
            print("[STT] all models failed; last error:", repr(last_error))
        else:
            print("[STT] transcription produced empty text even after fallbacks")
        return

    # â˜… ãƒ­ã‚°: éŸ³å£°èªè­˜ãƒ†ã‚­ã‚¹ãƒˆãƒ»ç™ºè¨€è€…ãƒ»è¨˜éŒ²æ™‚åˆ»ï¼ˆè¿‘ä¼¼ï¼‰
    dest_id = getattr(channel, "id", 0)
    await log_stt_event(
        guild_id=guild_id,
        dest_channel_id=dest_id,
        user_id=user_id,
        user_display=username,
        text=text,
        duration=float(dur) if dur is not None else None,
        rms=float(rms) if rms is not None else None,
        dbfs=float(db) if db is not None else None,
    )

    if used_model and used_model != st.get("stt_primary_model"):
        print(f"[STT] fallback model used: {used_model}")

    fallback_used = bool(used_model and used_model != (st.get("stt_primary_model") or DEFAULT_PRIMARY_STT_MODEL))
    estimated_cost = _estimate_stt_cost(used_model or "", dur or 0.0)
    token_count = used_metrics.get("token_count") if used_metrics else None
    await log_stt_metrics(
        guild_id=guild_id,
        user_id=user_id,
        model=used_model or "unknown",
        fallback_used=fallback_used,
        duration=float(dur) if isinstance(dur, (int, float)) else None,
        avg_logprob=used_metrics.get("avg_logprob") if used_metrics else None,
        no_speech_prob=used_metrics.get("no_speech_prob") if used_metrics else None,
        compression_ratio=used_metrics.get("compression_ratio") if used_metrics else None,
        token_count=token_count if isinstance(token_count, (int, float)) else None,
        estimated_cost=estimated_cost,
        text_length=len(text or ""),
    )

    metrics_state = st.get("stt_metrics")
    if isinstance(metrics_state, dict):
        metrics_state["total_calls"] = metrics_state.get("total_calls", 0) + 1
        if fallback_used:
            metrics_state["fallback_calls"] = metrics_state.get("fallback_calls", 0) + 1
        metrics_state["total_duration"] = metrics_state.get("total_duration", 0.0) + (float(dur) if isinstance(dur, (int, float)) else 0.0)
        metrics_state["total_cost"] = metrics_state.get("total_cost", 0.0) + estimated_cost
        usage = metrics_state.get("model_usage")
        if isinstance(usage, collections.Counter):
            usage[used_model or "unknown"] += 1
        else:
            metrics_state["model_usage"] = collections.Counter({used_model or "unknown": 1})

    # ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³æŠ•ç¨¿ï¼ˆé€£æŠ•ãƒãƒ¼ã‚¸å¯¾å¿œï¼‰
    await post_caption(guild_id, channel, user_id, username, jp_cleanup(text))


# =========================
# Help ã‚³ãƒãƒ³ãƒ‰ï¼ˆã‚«ã‚¹ã‚¿ãƒ ï¼‰
# =========================

def _is_admin_ctx(ctx: commands.Context) -> bool:
    perms = getattr(ctx.author, "guild_permissions", None)
    return bool(perms and (perms.manage_guild or perms.administrator))

# ã‚³ãƒãƒ³ãƒ‰å®šç¾©ï¼ˆæ›¸å¼ã¨èª¬æ˜ï¼‰
_HELP_ITEMS = [
    {
        "name": "join", "aliases": ["åŸ·äº‹å‚åŠ ","åŸ·äº‹å…¥å®¤","åŸ·äº‹å¬å–š"],
        "usage": "{p}join",
        "desc": "ä»Šã„ã‚‹ãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ«ã¸ãƒœãƒƒãƒˆã‚’å‚åŠ ã•ã›ã¾ã™ï¼ˆStage ã§ã¯è©±è€…åŒ–ã‚’è©¦ã¿ã¾ã™ï¼‰ã€‚ä¾‹: `{p}join`",
    },
    {
        "name": "leave", "aliases": ["åŸ·äº‹é€€å‡º","åŸ·äº‹é›¢è„±"],
        "usage": "{p}leave",
        "desc": "ãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ«ã‹ã‚‰é€€å‡ºã—ã¾ã™ã€‚ä¾‹: `{p}leave`",
    },
    {
        "name": "readon", "aliases": ["èª­ã¿ä¸Šã’ã‚³ãƒãƒ³ãƒ‰","èª­ã¿ä¸Šã’","èª­ã¿ä¸Šã’é–‹å§‹","èª­ã¿ä¸Šã’ã‚ªãƒ³","ã“ã®ãƒãƒ£ãƒ³ãƒãƒ«ã‚’èª­ã¿ä¸Šã’"],
        "usage": "{p}readon",
        "desc": "ã“ã®ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ãƒãƒ«ã®æ–°è¦ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ«ã§èª­ã¿ä¸Šã’ã¾ã™ã€‚ä¾‹: `{p}readon`",
    },
    {
        "name": "readoff", "aliases": ["èª­ã¿ä¸Šã’åœæ­¢","èª­ã¿ä¸Šã’ã‚ªãƒ•"],
        "usage": "{p}readoff",
        "desc": "èª­ã¿ä¸Šã’ã‚’åœæ­¢ã—ã¾ã™ã€‚ä¾‹: `{p}readoff`",
    },
    {
        "name": "readhere", "aliases": ["ã“ã“ã‚’èª­ã¿ä¸Šã’"],
        "usage": "{p}readhere",
        "desc": "èª­ã¿ä¸Šã’å¯¾è±¡ãƒãƒ£ãƒ³ãƒãƒ«ã‚’â€œä»Šã“ã“â€ã«å¤‰æ›´ã—ã¾ã™ã€‚ä¾‹: `{p}readhere`",
    },
    {
        "name": "stton", "aliases": ["å­—å¹•é–‹å§‹","æ–‡å­—èµ·ã“ã—é–‹å§‹","å­—å¹•ã‚ªãƒ³","éŸ³å£°èªè­˜é–‹å§‹"],
        "usage": "{p}stton [vad|fixed] [åŒºåˆ‡ã‚Šç§’æ•°(3-60)]",
        "desc": "ãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ«ã®éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—ã—ã¾ã™ã€‚æ—¢å®šã¯VADãƒ¢ãƒ¼ãƒ‰ã€‚ä¾‹: `{p}stton`, `{p}stton fixed 8`",
    },
    {
        "name": "sttoff", "aliases": ["å­—å¹•åœæ­¢","æ–‡å­—èµ·ã“ã—åœæ­¢","å­—å¹•ã‚ªãƒ•","éŸ³å£°èªè­˜åœæ­¢"],
        "usage": "{p}sttoff",
        "desc": "éŸ³å£°èªè­˜ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’åœæ­¢ã—ã¾ã™ã€‚ä¾‹: `{p}sttoff`",
    },
    {
        "name": "stttest", "aliases": ["æ–‡å­—èµ·ã“ã—ãƒ†ã‚¹ãƒˆ"],
        "usage": "{p}stttest",
        "desc": "gTTSâ†’Whisper ã®ç–é€šãƒ†ã‚¹ãƒˆã‚’è¡Œã„ã¾ã™ï¼ˆæ—¥æœ¬èªå›ºå®šï¼‰ã€‚ä¾‹: `{p}stttest`",
    },
    {
        "name": "rectest", "aliases": ["éŒ²éŸ³ãƒ†ã‚¹ãƒˆ"],
        "usage": "{p}rectest [ç§’æ•°(2-30)]",
        "desc": "ç¾åœ¨ã®ãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ«ã‚’ä¸€æ™‚éŒ²éŸ³ã—ã€çµæœã‚’è¿”ä¿¡ã—ã¾ã™ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰ã€‚ä¾‹: `{p}rectest 5`",
    },
    {
        "name": "diag", "aliases": ["è¨ºæ–­"],
        "usage": "{p}diag",
        "desc": "py-cord ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚„ ffmpeg/PyNaCl ãªã©ã®è¨ºæ–­æƒ…å ±ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚ä¾‹: `{p}diag`",
    },
    {
        "name": "whereami", "aliases": [],
        "usage": "{p}whereami",
        "desc": "ã“ã®ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ãƒãƒ«ï¼ˆã¾ãŸã¯ã‚¹ãƒ¬ãƒƒãƒ‰ï¼‰ã®æƒ…å ±ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚ä¾‹: `{p}whereami`",
    },
    {
        "name": "intentcheck", "aliases": [],
        "usage": "{p}intentcheck",
        "desc": "Members Intent ç­‰ã®å®Ÿéš›ã®æŒ™å‹•ã‚’ç°¡æ˜“ãƒã‚§ãƒƒã‚¯ã—ã¾ã™ã€‚ä¾‹: `{p}intentcheck`",
    },
    {
        "name": "sttset", "aliases": [],
        "usage": (
            "{p}sttset <key> <value> / key: vad | vaddb | mindur | merge | mergeauto | lang | thread | "
            "mode | window | vadlevel | vadsilence | vadpre | vadpost | vadoverlap | denoise | denoisemode | denoisemodel | denoisehp | denoiselp | denoisestr | denoisegain | sttmodel | sttmodel2"
        ),
        "desc": (
            "VADãƒ»ãƒã‚¤ã‚ºæŠ‘åœ§ãƒ»åˆ©ç”¨ãƒ¢ãƒ‡ãƒ«ãªã©èªè­˜è¨­å®šã‚’èª¿æ•´ã—ã¾ã™ï¼ˆè¨€èªã¯æ—¥æœ¬èªå›ºå®šï¼‰ã€‚"
            " ä¾‹: `{p}sttset vad 0.008`, `{p}sttset vadlevel 3`, `{p}sttset sttmodel gpt-4o-mini-transcribe`"
        ),
    },
    {
        "name": "sttstats", "aliases": ["sttçµ±è¨ˆ", "sttmetrics"],
        "usage": "{p}sttstats",
        "desc": "ãƒ¢ãƒ‡ãƒ«ä½¿ç”¨å›æ•°ã‚„ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç‡ã€æƒ³å®šã‚³ã‚¹ãƒˆãªã©ã€ç›´è¿‘ã®éŸ³å£°èªè­˜æŒ‡æ¨™ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚ä¾‹: `{p}sttstats`",
    },
    {
        "name": "sttcolor", "aliases": ["å­—å¹•è‰²", "color"],
        "usage": "{p}sttcolor [export/import/ãƒ¦ãƒ¼ã‚¶ãƒ¼]",
        "desc": "å­—å¹•ã®è‰²ã‚’ç®¡ç†ã—ã¾ã™ã€‚0-15 ã®ãƒ‘ãƒ¬ãƒƒãƒˆæŒ‡å®šã‚„è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å…¥å‡ºåŠ›ã«å¯¾å¿œã—ã¾ã™ã€‚ä¾‹: `{p}sttcolor @è‡ªåˆ† 3`",
    },
    {
        "name": "voicevoxstyles", "aliases": ["voxstyles", "voxlist"],
        "usage": "{p}voicevoxstyles",
        "desc": "VOICEVOX ã®è©±è€…IDã¨ã‚¹ã‚¿ã‚¤ãƒ«åã®ä¸€è¦§ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚ä¾‹: `{p}voicevoxstyles`",
    },
    {
        "name": "sttpalette", "aliases": ["colorpalette", "palette"],
        "usage": "{p}sttpalette",
        "desc": "å­—å¹•ã‚«ãƒ©ãƒ¼ã®ãƒ‘ãƒ¬ãƒƒãƒˆç•ªå·ã¨ã‚«ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰ã‚’ç¢ºèªã—ã¾ã™ã€‚ä¾‹: `{p}sttpalette`",
    },
    {
        "name": "voxdict", "aliases": ["è¾æ›¸ç®¡ç†"],
        "usage": "{p}voxdict <export|import|add>",
        "desc": "VOICEVOX ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼è¾æ›¸ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ/ã‚¤ãƒ³ãƒãƒ¼ãƒˆ/è¿½åŠ ã—ã¾ã™ã€‚ä¾‹: `{p}voxdict add ãƒ†ã‚¹ãƒˆ ãƒ†ã‚¹ãƒˆ`",
    },
    # ==== ç®¡ç†è€…å‘ã‘ï¼ˆè¡¨ç¤ºåˆ¶å¾¡ï¼‰ ====
    {
        "name": "ttsspeed", "aliases": ["èª­ã¿ä¸Šã’é€Ÿåº¦"],
        "usage": "{p}ttsspeed <å€ç‡>",
        "desc": "ã‚µãƒ¼ãƒãƒ¼å…¨ä½“ã®åŸºæº–è©±é€Ÿã‚’è¨­å®šã—ã¾ã™ã€‚ä¾‹: `{p}ttsspeed 1.35`ï¼ˆæ¨å¥¨ 0.6ã€œ2.0ï¼‰",
        "admin_only": True,
    },
    {
        "name": "ttsvoice", "aliases": ["å£°è‰²"],
        "usage": "{p}ttsvoice @ãƒ¦ãƒ¼ã‚¶ãƒ¼ (<åŠéŸ³> [ãƒ†ãƒ³ãƒ] | reset)",
        "desc": "ç‰¹å®šãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å£°è‰²ï¼ˆåŠéŸ³ï¼‰ã¨ãƒ†ãƒ³ãƒä¿‚æ•°ã‚’ä¸Šæ›¸ãã—ã¾ã™ï¼ˆgTTS åˆ©ç”¨æ™‚ã®ã¿ï¼‰ã€‚ä¾‹: `{p}ttsvoice @å¤ªéƒ +3 1.10` / `{p}ttsvoice @å¤ªéƒ reset`",
        "admin_only": True,
    },
    {
        "name": "ttsconfig", "aliases": ["èª­ã¿ä¸Šã’è¨­å®š"],
        "usage": "{p}ttsconfig",
        "desc": "ç¾åœ¨ã®è©±é€Ÿãƒ»å€‹åˆ¥å£°è‰²ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ã®ä¸€è¦§ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚ä¾‹: `{p}ttsconfig`",
        "admin_only": True,
    },
    {
        "name": "ttsspeaker", "aliases": ["ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼", "speaker"],
        "usage": "{p}ttsspeaker [default/export/import/ãƒ¦ãƒ¼ã‚¶ãƒ¼]",
        "desc": "VOICEVOX ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè©±è€…ã‚„ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ¥è©±è€…IDã‚’ç®¡ç†ã—ã¾ã™ï¼ˆVOICEVOX åˆ©ç”¨æ™‚ã®ã¿ï¼‰ã€‚ä¾‹: `{p}ttsspeaker default 2`",
        "admin_only": True,
    },
    {
        "name": "logs", "aliases": ["ãƒ­ã‚°å–å¾—", "getlogs"],
        "usage": "{p}logs",
        "desc": "TTS/STT ã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆCSVï¼‰ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚ä¾‹: `{p}logs`",
    },
]

def _find_help_item(name: str):
    n = name.lower()
    for item in _HELP_ITEMS:
        if item["name"].lower() == n or n in [a.lower() for a in item.get("aliases", [])]:
            return item
    return None

def _format_cmd_line(item: dict, prefix: str) -> tuple[str, str]:
    """Embed ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ (name, value) ã‚’è¿”ã™"""
    aliases = item.get("aliases") or []
    alias_str = (" / " + " / ".join(aliases)) if aliases else ""
    admin_tag = " ğŸ”’" if item.get("admin_only") else ""
    name = f"{prefix}{item['name']}{alias_str}{admin_tag}"
    usage = (item["usage"] or "").format(p=prefix)
    desc = (item["desc"] or "").format(p=prefix)
    value = f"**æ›¸å¼**: `{usage}`\n{desc}"
    return name, value

@bot.command(name="help", aliases=["h"])
async def help_command(ctx: commands.Context, *, command_name: str = None):
    """ã‚«ã‚¹ã‚¿ãƒ ãƒ˜ãƒ«ãƒ—: !help / !help <ã‚³ãƒãƒ³ãƒ‰å>"""
    prefix = ctx.prefix or "!"
    is_admin = _is_admin_ctx(ctx)

    # å€‹åˆ¥ãƒ˜ãƒ«ãƒ—ï¼ˆ!help stton ã®ã‚ˆã†ã«æŒ‡å®šã•ã‚ŒãŸå ´åˆï¼‰
    if command_name:
        item = _find_help_item(command_name)
        if not item:
            return await ctx.reply(f"`{command_name}` ã®ãƒ˜ãƒ«ãƒ—ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚`{prefix}help` ã§ä¸€è¦§ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
        if item.get("admin_only") and not is_admin:
            return await ctx.reply("ã“ã®ã‚³ãƒãƒ³ãƒ‰ã¯ã‚µãƒ¼ãƒãƒ¼ç®¡ç†è€…å‘ã‘ã§ã™ã€‚")
        name, value = _format_cmd_line(item, prefix)
        emb = discord.Embed(
            title="ğŸ“– ã‚³ãƒãƒ³ãƒ‰ãƒ˜ãƒ«ãƒ—",
            description=f"`{prefix}{item['name']}` ã®èª¬æ˜ã§ã™ã€‚",
            color=discord.Color.blurple(),
        )
        emb.add_field(name=name, value=value, inline=False)
        return await ctx.reply(embed=emb)

    # ä¸€è¦§ãƒ˜ãƒ«ãƒ—
    emb = discord.Embed(
        title="ğŸ“– ãƒ˜ãƒ«ãƒ— â€” ãƒœã‚¤ã‚¹å­—å¹•ãƒœãƒƒãƒˆ",
        description=(
            f"ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹: `{prefix}`\n"
            f"è©³ç´°ã¯ `{prefix}help <ã‚³ãƒãƒ³ãƒ‰å>` ã§ç¢ºèªã§ãã¾ã™ã€‚"
        ),
        color=discord.Color.blurple(),
    )

    # å®Ÿè¡Œè€…ãŒä½¿ãˆã‚‹ã‚³ãƒãƒ³ãƒ‰ã®ã¿è¡¨ç¤º
    visible_items = [
        x for x in _HELP_ITEMS
        if (not x.get("admin_only") or is_admin)
    ]

    # è¦‹ã‚„ã™ã„é †ã«ä¸¦ã¹æ›¿ãˆï¼ˆãŠå¥½ã¿ã§ï¼‰
    order = ["join","leave","readon","readoff","readhere","stton","sttoff",
             "stttest","rectest","diag","logs","whereami","intentcheck","sttset",
             "sttcolor","sttpalette","voicevoxstyles","voxdict","ttsspeed","ttsvoice","ttsconfig","ttsspeaker"]
    sort_key = {name:i for i,name in enumerate(order)}
    visible_items.sort(key=lambda x: sort_key.get(x["name"], 999))

    for item in visible_items:
        name, value = _format_cmd_line(item, prefix)
        emb.add_field(name=name, value=value, inline=False)

    # ãƒ•ãƒƒã‚¿ãƒ¼
    if not is_admin:
        emb.set_footer(text="ğŸ”’ ãŒä»˜ã„ãŸé …ç›®ã¯ã‚µãƒ¼ãƒãƒ¼ç®¡ç†è€…å‘ã‘ã§ã™ã€‚")
    else:
        emb.set_footer(text="ç®¡ç†è€…å‘ã‘ã®ã‚³ãƒãƒ³ãƒ‰ã‚‚è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚")

    await ctx.reply(embed=emb)

# === CCFOLIA BRIDGE START: web server & pump ===
def _ip_allowed(remote: str) -> bool:
    if not CCFO_ACCEPT_FROM:
        return True
    host = (remote or "").split(":")[0]
    return (remote in CCFO_ACCEPT_FROM) or (host in CCFO_ACCEPT_FROM)

# CORS ãƒ˜ãƒƒãƒ€ï¼ˆå¿…è¦ã«å¿œã˜ã¦ Origin ã‚’åˆ¶é™ã—ãŸã‘ã‚Œã° "*" ã‚’ "https://ccfolia.com" ã«ï¼‰
def _cors_headers(origin: str | None) -> dict:
    allow_origin = origin if origin else "*"
    return {
        "Access-Control-Allow-Origin": allow_origin,
        "Vary": "Origin",
        "Access-Control-Allow-Methods": "POST, OPTIONS",
        "Access-Control-Allow-Headers": "Content-Type, X-CCF-Token",
        "Access-Control-Max-Age": "600",
        # PNAï¼ˆãƒ­ãƒ¼ã‚«ãƒ«å®›ã¦ï¼‰ã‚’è¨±å¯ï¼ˆChromeç³»ï¼‰
        "Access-Control-Allow-Private-Network": "true",
    }

async def ccfo_options_handler(request: web.Request):
    # ãƒ—ãƒªãƒ•ãƒ©ã‚¤ãƒˆã¸ 200 å¿œç­” + CORS ãƒ˜ãƒƒãƒ€
    origin = request.headers.get("Origin")
    return web.Response(status=200, headers=_cors_headers(origin))

async def ccfo_post_handler(request: web.Request):
    print('start:ccfo_post_handler') # for debug
    origin = request.headers.get("Origin")
    # IP/Token ãƒã‚§ãƒƒã‚¯ã¯ã“ã‚Œã¾ã§é€šã‚Š
    if not _ip_allowed(request.remote or ""):
        return web.json_response({"ok": False, "error": "forbidden_ip"}, status=403, headers=_cors_headers(origin))
    token = request.headers.get("X-CCF-Token", "")
    if CCFO_SECRET and token != CCFO_SECRET:
        return web.json_response({"ok": False, "error": "bad_token"}, status=401, headers=_cors_headers(origin))
    try:
        data = await request.json()
    except Exception:
        return web.json_response({"ok": False, "error": "invalid_json"}, status=400, headers=_cors_headers(origin))

    spk = (data.get("speaker") or "ï¼ˆæœªæŒ‡å®šï¼‰").strip()
    txt = (data.get("text") or "").strip()
    room = (data.get("room") or "").strip()
    ts_client = (data.get("ts_client") or "").strip()
    print(['speaker',spk]) # for debug
    print(['text',txt]) # for debug
    print(['room',room]) # for debug
    print(['ts_client',ts_client]) # for debug
    await log_ccfolia_event(user_display=spk,text=txt)
    if not txt:
        return web.json_response({"ok": False, "error": "empty_text"}, status=400, headers=_cors_headers(origin))

    await ccfo_queue.put({"speaker": spk, "text": txt, "room": room, "ts_client": ts_client})
    print('check:ccfo_queue') # for debug
    print(ccfo_queue) # for debug
    print('end:ccfo_post_handler') # for debug
    return web.json_response({"ok": True}, headers=_cors_headers(origin))


async def _start_ccfo_web_server():
    app = web.Application()
    app.add_routes([
        web.post("/ccfolia_event", ccfo_post_handler),
        web.options("/ccfolia_event", ccfo_options_handler),  # â† è¿½åŠ 
    ])
    runner = web.AppRunner(app)
    await runner.setup()
    site = web.TCPSite(runner, host=CCFO_HOST, port=CCFO_PORT)
    await site.start()
    print(f"[CCFOLIA] bridge server started at http://{CCFO_HOST}:{CCFO_PORT}")

def _resolve_ccfo_speaker_id(name: str) -> int:
    return int(CCFO_SPK_MAP.get(name, CCFO_SPK_MAP.get("ï¼ˆæœªæŒ‡å®šï¼‰", CCFO_DEFAULT_SPK)))

async def _ccfo_send_text(ch: discord.TextChannel, speaker: str, text: str, room: str, ts_client: str):
    header = f"[{room}] {speaker}" if room else speaker
    stamp = f" `({ts_client})`" if ts_client else ""
    content = f"**{header}**{stamp}\n{text}"
    print(['content',content]) # for debug
    print(ch) # for debug
    await ch.send(content)

async def _ccfo_send_voicevox_file(ch: discord.TextChannel, speaker: str, text: str, spk_id: int):
    # æ—¢å­˜ã® VOICEVOX åŒæœŸé–¢æ•°ã‚’æµç”¨
    try:
        wav = await _voicevox_synthesize(sanitize_for_tts(text), spk_id)
    except Exception as e:
        await ch.send(f"ã€TTSå¤±æ•—:{speaker}ã€‘{e!r}")
        return
    bio = io.BytesIO(wav); bio.seek(0)
    await ch.send(file=discord.File(bio, filename=f"{speaker}.wav"))

async def _ccfo_play_in_vc(guild: discord.Guild, text: str, spk_id: int):
    vc = guild.voice_client
    if not vc or not vc.is_connected():
        return False
    # ç›´æ¥ VOICEVOX ã§åˆæˆ â†’ ä¸€æ™‚WAV â†’ VC å†ç”Ÿ
    try:
        wav = await _voicevox_synthesize(sanitize_for_tts(text), spk_id)
    except Exception as e:
        print("[CCFOLIA] VC TTS failed:", repr(e))
        return False
    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as f:
        tmp = f.name; f.write(wav)
    try:
        await _play_vc_audio(vc, tmp)
        return True
    finally:
        try: os.remove(tmp)
        except: pass

async def ccfo_pump_worker():
    await bot.wait_until_ready()
    if not CCFO_MIRROR_CH_ID:
        print("[CCFOLIA] WARNING: CCFOLIA_MIRROR_CHANNEL_ID is not set; events will be dropped.")
    print(['CCFO_MIRROR_CH_ID:',CCFO_MIRROR_CH_ID]) # for debug
    text_ch = bot.get_channel(CCFO_MIRROR_CH_ID) if CCFO_MIRROR_CH_ID else None

    while True:
        ev = await ccfo_queue.get()
        print('check:ccfo_queue') # for debug
        print(ccfo_queue) # for debug
        sp = ev.get("speaker") or "ï¼ˆæœªæŒ‡å®šï¼‰"
        tx = ev.get("text") or ""
        room = ev.get("room") or ""
        ts_client = ev.get("ts_client") or ""
        spk_id = _resolve_ccfo_speaker_id(sp)
        
        if not text_ch:
            text_ch = bot.get_channel(CCFO_MIRROR_CH_ID) if CCFO_MIRROR_CH_ID else None

        print(['speaker',sp]) # for debug
        print(['text',tx]) # for debug
        print(['room',room]) # for debug
        print(['ts_client',ts_client]) # for debug
        print(['spk_id',spk_id]) # for debug
        print(['text_ch',text_ch]) # for debug

        # 1) ãƒ†ã‚­ã‚¹ãƒˆãƒŸãƒ©ãƒ¼
        if isinstance(text_ch, discord.TextChannel):
            print(['ccfolia event send to discord :text:',sp,',',tx]) # for debug
            await _ccfo_send_text(text_ch, sp, tx, room, ts_client)

        # 2) TTS
        if CCFO_TTS_MODE == "file":
            if isinstance(text_ch, discord.TextChannel):
                await _ccfo_send_voicevox_file(text_ch, sp, tx, spk_id)
        elif CCFO_TTS_MODE == "voice":
            ## æœªæŒ‡å®šã¯èª­ã¿ä¸Šã’ãªã„ã€‚
            #if sp == "ï¼ˆæœªæŒ‡å®šï¼‰":
            #    break
            # æœ€åˆã®ã‚®ãƒ«ãƒ‰ã«å¯¾ã—ã¦ VC å†ç”Ÿã‚’è©¦ã¿ã‚‹ï¼ˆå¿…è¦ãªã‚‰ env ã§ GUILD å›ºå®šã‚‚å¯ï¼‰
            guilds = bot.guilds
            ok = False
            for g in guilds:
                ok = await _ccfo_play_in_vc(g, f"{sp}ï¼š{tx}", spk_id)
                if ok:
                    break
            if not ok and isinstance(text_ch, discord.TextChannel):
                await text_ch.send("ï¼ˆVCæœªæ¥ç¶šã®ãŸã‚TTSã¯å†ç”Ÿã§ãã¾ã›ã‚“ã§ã—ãŸï¼‰")

# èµ·å‹•æ™‚ã« webã‚µãƒ¼ãƒ ã¨ ãƒãƒ³ãƒ—ã‚’èµ·å‹•
_original_on_ready = bot.on_ready

@bot.event
async def on_ready():
    # æ—¢å­˜ã® on_ready ãƒ­ã‚¸ãƒƒã‚¯ã‚’ç¶­æŒ
    if _original_on_ready:
        try:
            await _original_on_ready()
        except TypeError:
            # æ—¢å­˜ãŒåŒæœŸé–¢æ•°ã®å¯èƒ½æ€§ã«ã‚‚ä¸€å¿œé…æ…®
            pass
    # ä¸€åº¦ã ã‘èµ·å‹•
    if not getattr(bot, "_ccfo_server_started", False):
        bot._ccfo_server_started = True
        bot.loop.create_task(_start_ccfo_web_server())
        bot.loop.create_task(ccfo_pump_worker())
        print("[CCFOLIA] pump & server tasks started")
# === CCFOLIA BRIDGE END ===


def main() -> None:
    if not TOKEN:
        raise RuntimeError("DISCORD_TOKEN is not set. Update your environment or .env file.")
    bot.run(TOKEN)


if __name__ == "__main__":
    main()
